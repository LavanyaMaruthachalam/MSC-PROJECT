{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "s6Th_i1Sn09C"
      ],
      "mount_file_id": "1-BEITKaV85-u1JQGyfOab4aXkFFdB3Qr",
      "authorship_tag": "ABX9TyMJd7Kmh3+sahC8RswYLafN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "989b76d0cbe24d4e9c805b6da99a0b52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2146741e877d466c820145df94100d7d",
              "IPY_MODEL_3da41766198749bcb6412701fa373481",
              "IPY_MODEL_348856135a374947920447478288b3b0"
            ],
            "layout": "IPY_MODEL_b8558ea56e624e879b6401b1c01b0cc1"
          }
        },
        "2146741e877d466c820145df94100d7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7dc836e861bf437b8ae3f532b8e89210",
            "placeholder": "​",
            "style": "IPY_MODEL_d8760320c31e4abf892d96286105758c",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "3da41766198749bcb6412701fa373481": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0906d3cde1074ca98a0224a34defae2c",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3b8a64ee528b466f909b9f385ab8e3e5",
            "value": 26
          }
        },
        "348856135a374947920447478288b3b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a6492b0a6714af7bf6512c448eb1b22",
            "placeholder": "​",
            "style": "IPY_MODEL_df1b4cb675ac4c65ac2fce5a80d33233",
            "value": " 26.0/26.0 [00:00&lt;00:00, 601B/s]"
          }
        },
        "b8558ea56e624e879b6401b1c01b0cc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dc836e861bf437b8ae3f532b8e89210": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8760320c31e4abf892d96286105758c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0906d3cde1074ca98a0224a34defae2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b8a64ee528b466f909b9f385ab8e3e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a6492b0a6714af7bf6512c448eb1b22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df1b4cb675ac4c65ac2fce5a80d33233": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8b984a2c19e4bb0ad996d095f125c13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5806094ee27640d293a0686b864216d7",
              "IPY_MODEL_13ccf522d7e1493fb69f0fb2b8f61df6",
              "IPY_MODEL_d161afe13774417b8f2126fce830a9ad"
            ],
            "layout": "IPY_MODEL_de2d50cf4eaa4cf7bd0f59e42c6021c6"
          }
        },
        "5806094ee27640d293a0686b864216d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba0617194ec441f285f2c9fe72b9da33",
            "placeholder": "​",
            "style": "IPY_MODEL_c2c027ffb8614cc6be60c9de448505a2",
            "value": "vocab.json: 100%"
          }
        },
        "13ccf522d7e1493fb69f0fb2b8f61df6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5f8339972d04e7abebaea8428d8aaeb",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9210a0d0f15b4d3e985d4bb8d843c577",
            "value": 1042301
          }
        },
        "d161afe13774417b8f2126fce830a9ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d69e4dc12d334839bf27ffb58c6421e2",
            "placeholder": "​",
            "style": "IPY_MODEL_0d7cd8a72d1f40d3ad9d0b1b831a493b",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 4.26MB/s]"
          }
        },
        "de2d50cf4eaa4cf7bd0f59e42c6021c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba0617194ec441f285f2c9fe72b9da33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2c027ffb8614cc6be60c9de448505a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5f8339972d04e7abebaea8428d8aaeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9210a0d0f15b4d3e985d4bb8d843c577": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d69e4dc12d334839bf27ffb58c6421e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d7cd8a72d1f40d3ad9d0b1b831a493b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67a24b00b41b494c859fb1a83190a9a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b2432f7336024892a5f7789cab0bef63",
              "IPY_MODEL_935b42ff162d4620aadef9e6c63bb87f",
              "IPY_MODEL_a378f7980f634ffbae752a6f8a2640ea"
            ],
            "layout": "IPY_MODEL_763b778cb85046528e73ab1ac0f58eb4"
          }
        },
        "b2432f7336024892a5f7789cab0bef63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c16a6ebbfd8145f3b8aa501084251332",
            "placeholder": "​",
            "style": "IPY_MODEL_ddf07a831d1d4057a796f41edbf85538",
            "value": "merges.txt: 100%"
          }
        },
        "935b42ff162d4620aadef9e6c63bb87f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a58c0f389fa7476c99867371e92f3b2f",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_47da4329829141ffa163d79a7244c9c1",
            "value": 456318
          }
        },
        "a378f7980f634ffbae752a6f8a2640ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e9cad36a3fc4e2d9448738035656c47",
            "placeholder": "​",
            "style": "IPY_MODEL_3e5f582f0a6f46e79689f8d5c2fc605d",
            "value": " 456k/456k [00:00&lt;00:00, 1.85MB/s]"
          }
        },
        "763b778cb85046528e73ab1ac0f58eb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c16a6ebbfd8145f3b8aa501084251332": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddf07a831d1d4057a796f41edbf85538": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a58c0f389fa7476c99867371e92f3b2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47da4329829141ffa163d79a7244c9c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e9cad36a3fc4e2d9448738035656c47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e5f582f0a6f46e79689f8d5c2fc605d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ce7d08003a84e469bc9e9c882af88b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_633b1d57eb9f470a83361f2d2b3cf3fe",
              "IPY_MODEL_59cfd2a418a3461c83a5c225448b97d6",
              "IPY_MODEL_38605d6089f94c70aa5a06a3db311edc"
            ],
            "layout": "IPY_MODEL_e97b574ee9be4ac1813d5f689eb1a56a"
          }
        },
        "633b1d57eb9f470a83361f2d2b3cf3fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_286aceae1c294f8cad379fa65b6608c5",
            "placeholder": "​",
            "style": "IPY_MODEL_a8b011b875aa4c8bb6a0919b48339098",
            "value": "tokenizer.json: 100%"
          }
        },
        "59cfd2a418a3461c83a5c225448b97d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc5305d13483401f861d6c5d2ebd7c3d",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_07557da5c9f449349a1287c9fa91dc36",
            "value": 1355256
          }
        },
        "38605d6089f94c70aa5a06a3db311edc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e996324dac94aa8b006b88dafb9abb2",
            "placeholder": "​",
            "style": "IPY_MODEL_752ee8d07b374cc696636bc8a24c3db1",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 5.45MB/s]"
          }
        },
        "e97b574ee9be4ac1813d5f689eb1a56a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "286aceae1c294f8cad379fa65b6608c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8b011b875aa4c8bb6a0919b48339098": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc5305d13483401f861d6c5d2ebd7c3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07557da5c9f449349a1287c9fa91dc36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e996324dac94aa8b006b88dafb9abb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "752ee8d07b374cc696636bc8a24c3db1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "602b748598c44c3c9af66b3b2d9c9137": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a7deec7fd5b44b87b3d7d8b0842770b3",
              "IPY_MODEL_cb04739c6a8346a1b1441abc2d414418",
              "IPY_MODEL_5d267d5c594f42d6b4729f3bdf2ba0ea"
            ],
            "layout": "IPY_MODEL_938a5d59cb7d41c7866c854bc61bd8c5"
          }
        },
        "a7deec7fd5b44b87b3d7d8b0842770b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8138458bdc104a1eb885fc8bdc46b64b",
            "placeholder": "​",
            "style": "IPY_MODEL_6b20164464904dea8f704f176617bbd1",
            "value": "config.json: 100%"
          }
        },
        "cb04739c6a8346a1b1441abc2d414418": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e466f635986c4621bff414b74962763b",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1a8beb54a49646108522eddb27f1cc13",
            "value": 665
          }
        },
        "5d267d5c594f42d6b4729f3bdf2ba0ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_112b9a7040464accae51635a0367b88a",
            "placeholder": "​",
            "style": "IPY_MODEL_01d7ebd0f14b4004a9b3bbc16da08746",
            "value": " 665/665 [00:00&lt;00:00, 20.9kB/s]"
          }
        },
        "938a5d59cb7d41c7866c854bc61bd8c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8138458bdc104a1eb885fc8bdc46b64b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b20164464904dea8f704f176617bbd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e466f635986c4621bff414b74962763b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a8beb54a49646108522eddb27f1cc13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "112b9a7040464accae51635a0367b88a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01d7ebd0f14b4004a9b3bbc16da08746": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f07c0790e5ed4f0688741545dd5e1675": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cfb32e18f3ae4bec81e4581f4af4f9e7",
              "IPY_MODEL_7c9605515a43412692a3f0a677cc4de4",
              "IPY_MODEL_45f88df21bc8414e91e11dde8f9dfc2f"
            ],
            "layout": "IPY_MODEL_5828ec60aed34f0cba1d250e10120b40"
          }
        },
        "cfb32e18f3ae4bec81e4581f4af4f9e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f043fe4f70148868109c35446921e48",
            "placeholder": "​",
            "style": "IPY_MODEL_30a27c4c5d8a454790c54819e3bfc880",
            "value": "model.safetensors: 100%"
          }
        },
        "7c9605515a43412692a3f0a677cc4de4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aca48123cfd042a9a26029a1387126b8",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e17ca888e2eb4816af606de6e405ea45",
            "value": 548105171
          }
        },
        "45f88df21bc8414e91e11dde8f9dfc2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4432cd47213d41cfb1b5e9b302505509",
            "placeholder": "​",
            "style": "IPY_MODEL_5c857b7b17684c8b98ef9e520b1ed7b6",
            "value": " 548M/548M [00:07&lt;00:00, 150MB/s]"
          }
        },
        "5828ec60aed34f0cba1d250e10120b40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f043fe4f70148868109c35446921e48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30a27c4c5d8a454790c54819e3bfc880": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aca48123cfd042a9a26029a1387126b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e17ca888e2eb4816af606de6e405ea45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4432cd47213d41cfb1b5e9b302505509": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c857b7b17684c8b98ef9e520b1ed7b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ce85e9ebcd1422f9ec5f4525d222912": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7deb9579bcc14a90b31fb1c17e4fdf85",
              "IPY_MODEL_fa74c420613b43e4b79d26dfc596969e",
              "IPY_MODEL_78a198008a034ce391e0d8164f2cc55b"
            ],
            "layout": "IPY_MODEL_1cad3648357849a3b81477b2a8a1dd71"
          }
        },
        "7deb9579bcc14a90b31fb1c17e4fdf85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6287d1cf42cd4f98b877eb0e42d694dd",
            "placeholder": "​",
            "style": "IPY_MODEL_c7e10139ee9a49e5aebc8e074ad7b88c",
            "value": "generation_config.json: 100%"
          }
        },
        "fa74c420613b43e4b79d26dfc596969e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d18e2a8c837a43f8a271b6bdc8fa85f4",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8b8a268f5bb347fbb153169c3d73269e",
            "value": 124
          }
        },
        "78a198008a034ce391e0d8164f2cc55b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc5e555eeba04e22802e15dbbf7a152d",
            "placeholder": "​",
            "style": "IPY_MODEL_b15015a191614bb38adb921f5fa07d31",
            "value": " 124/124 [00:00&lt;00:00, 9.95kB/s]"
          }
        },
        "1cad3648357849a3b81477b2a8a1dd71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6287d1cf42cd4f98b877eb0e42d694dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7e10139ee9a49e5aebc8e074ad7b88c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d18e2a8c837a43f8a271b6bdc8fa85f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b8a268f5bb347fbb153169c3d73269e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dc5e555eeba04e22802e15dbbf7a152d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b15015a191614bb38adb921f5fa07d31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LavanyaMaruthachalam/MSc-Project/blob/main/Lavanya_Maruthachalam_CHATBOT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This initial model is is only used at the starting phase of the project.It is not linked with the current project code.The current project code is started frrom the heading of Rule based model."
      ],
      "metadata": {
        "id": "_3xWUEBR4FpA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initial model\n",
        "\n"
      ],
      "metadata": {
        "id": "s6Th_i1Sn09C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# import json\n",
        "# import csv\n",
        "# import json\n",
        "# import sqlite3\n",
        "\n",
        "\n",
        "# #Load JSON data\n",
        "# file_path = '/content/drive/MyDrive/THIRUKURAL/thirukural_git.json'\n",
        "# with open(file_path, 'r', encoding='utf-8') as file:\n",
        "#     data = json.load(file)['kurals']  # Adjust this depending on the structure of your JSON\n",
        "\n",
        "# #Prepare to write to CSV\n",
        "# csv_file_path = 'output.csv'\n",
        "# with open(csv_file_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "#     fieldnames = ['chapter', 'number', 'section', 'kural', 'meaning_ta_mu_va', 'meaning_ta_salamon', 'meaning_en']\n",
        "#     writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "#     writer.writeheader()\n",
        "\n",
        "#     for item in data:\n",
        "#         #Prepare data, combining kural parts\n",
        "#         kural_combined = ' '.join(item['kural'])\n",
        "\n",
        "#         row = {\n",
        "#             'chapter': item['chapter'],\n",
        "#             'number': item['number'],\n",
        "#             'section': item['section'],\n",
        "#             'kural': kural_combined,\n",
        "#             'meaning_ta_mu_va': item['meaning'].get('ta_mu_va', ''),\n",
        "#             'meaning_ta_salamon': item['meaning'].get('ta_salamon', ''),\n",
        "#             'meaning_en': item['meaning'].get('en', '')\n",
        "#         }\n",
        "#         writer.writerow(row)\n",
        "\n",
        "# print(f\"Data has been written to {csv_file_path}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "L0hyLUm_a7UI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Connect to SQLite database (or create it if it doesn't exist)\n",
        "# conn = sqlite3.connect('kurals.db')\n",
        "# c = conn.cursor()\n",
        "\n",
        "# # Define the table schema\n",
        "# c.execute('''\n",
        "# CREATE TABLE IF NOT EXISTS kural (\n",
        "#     id INTEGER PRIMARY KEY,\n",
        "#     chapter TEXT,\n",
        "#     number INTEGER,\n",
        "#     section TEXT,\n",
        "#     kural TEXT,\n",
        "#     meaning_ta_mu_va TEXT,\n",
        "#     meaning_ta_salamon TEXT,\n",
        "#     meaning_en TEXT\n",
        "# )\n",
        "# ''')\n",
        "\n",
        "# # Insert data into the table\n",
        "# for item in data:\n",
        "#     kural_combined = ' '.join(item['kural'])  # Combine the kural parts into a single string\n",
        "\n",
        "#     c.execute('''\n",
        "#     INSERT INTO kural (chapter, number, section, kural, meaning_ta_mu_va, meaning_ta_salamon, meaning_en) VALUES (?, ?, ?, ?, ?, ?, ?)\n",
        "#     ''', (\n",
        "#         item['chapter'],\n",
        "#         item['number'],\n",
        "#         item['section'],\n",
        "#         kural_combined,\n",
        "#         item['meaning'].get('ta_mu_va', ''),\n",
        "#         item['meaning'].get('ta_salamon', ''),\n",
        "#         item['meaning'].get('en', '')\n",
        "#     ))\n",
        "\n",
        "# # Commit changes and close the connection\n",
        "# conn.commit()\n",
        "# conn.close()\n"
      ],
      "metadata": {
        "id": "6mg5O4VUSDNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **new**\n"
      ],
      "metadata": {
        "id": "8pFysGAXwDro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import googletrans  # Assuming usage of Google Translate for example purposes\n",
        "\n",
        "# def get_thirukkural_response(kural_data, query_type, query_value, translate_to=None, author_alias=None):\n",
        "#     \"\"\"Retrieve and optionally translate a Thirukkural response based on detailed criteria.\"\"\"\n",
        "#     translator = googletrans.Translator()\n",
        "#     responses = []\n",
        "\n",
        "#     def translate(text, target_lang):\n",
        "#         \"\"\"Helper function to translate text using Google Translate.\"\"\"\n",
        "#         if target_lang == 'en':\n",
        "#             return translator.translate(text, src='ta', dest='en').text\n",
        "#         elif target_lang == 'ta':\n",
        "#             return translator.translate(text, src='en', dest='ta').text\n",
        "#         return text\n",
        "\n",
        "#     # Process queries based on type\n",
        "#     kurals_to_process = []\n",
        "#     if query_type == 'kural_number':\n",
        "#         kural = next((k for k in kural_data['kurals'] if k['number'] == int(query_value)), None)\n",
        "#         if kural:\n",
        "#             kurals_to_process.append(kural)\n",
        "#     elif query_type in ['keyword', 'chapter_name', 'section_name']:\n",
        "#         if query_type == 'keyword':\n",
        "#             kurals_to_process = [k for k in kural_data['kurals'] if query_value.lower() in \" \".join(k['kural']).lower()]\n",
        "#         elif query_type == 'chapter_name':\n",
        "#             kurals_to_process = [k for k in kural_data['kurals'] if k['chapter'].lower() == query_value.lower()]\n",
        "#         elif query_type == 'section_name':\n",
        "#             kurals_to_process = [k for k in kural_data['kurals'] if k['section'].lower() == query_value.lower()]\n",
        "\n",
        "#     # Generate responses for each kural\n",
        "#     for kural in kurals_to_process:\n",
        "#         kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "#         if translate_to == 'ta':\n",
        "#             english_meaning = kural['meaning'].get('en', \"No English translation available.\")\n",
        "#             translated_text = translate(english_meaning, 'ta')\n",
        "#             responses.append(f\"{kural_text}\\nMeaning (Tamil): {translated_text}\")\n",
        "#         elif author_alias and author_alias in ['mu_va', 'salamon']:\n",
        "#             author_key = 'ta_' + author_alias if 'ta_' not in author_alias else author_alias\n",
        "#             explanation = kural['meaning'].get(author_key, \"No explanation available.\")\n",
        "#             translated_text = translate(explanation, 'en')\n",
        "#             responses.append(f\"{kural_text}\\nExplanation by {author_alias} (English): {translated_text}\")\n",
        "#         else:\n",
        "#             english_meaning = kural['meaning'].get('en', \"No English translation available.\")\n",
        "#             responses.append(f\"{kural_text}\\nMeaning (English): {english_meaning}\")\n",
        "\n",
        "#     return \"\\n\".join(responses) if responses else \"No Kural found matching the query.\"\n"
      ],
      "metadata": {
        "id": "oMGNR39xBRP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RULE BASED\n"
      ],
      "metadata": {
        "id": "Q9kIlZv6T3lm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxYies4_Wa3D",
        "outputId": "eecaad94-44cd-4065-da10-7d88a00632cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount Google drive to read data from it\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "!pip install openai==0.28\n",
        "!pip install googletrans==4.0.0-rc1\n",
        "!pip install googletrans==4.0.0-rc1 openai\n",
        "!pip install transformers torch\n",
        "!pip install transformers[torch] -U\n",
        "\n",
        "!pip install --upgrade pip\n",
        "!pip install --upgrade transformers\n",
        "!pip install --upgrade torch\n",
        "!pip install --upgrade accelerate\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4g4sAANlRxz",
        "outputId": "18b5cf0f-8f30-4522-c06e-28ca1d0a8de0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.30.1-py3-none-any.whl (320 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/320.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m256.0/320.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.30.1\n",
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.30.1\n",
            "    Uninstalling openai-1.30.1:\n",
            "      Successfully uninstalled openai-1.30.1\n",
            "Successfully installed openai-0.28.0\n",
            "Collecting googletrans==4.0.0-rc1\n",
            "  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting httpx==0.13.3 (from googletrans==4.0.0-rc1)\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2024.2.2)\n",
            "Collecting hstspreload (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hstspreload-2024.5.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.1)\n",
            "Collecting chardet==3.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna==2.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17395 sha256=48178180b6e0cc600db32b61c433cf375f5a9639984f1d1bad242c510c2a6c32\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/59/9f/7372f0cf70160fe61b528532e1a7c8498c4becd6bcffb022de\n",
            "Successfully built googletrans\n",
            "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\n",
            "  Attempting uninstall: h11\n",
            "    Found existing installation: h11 0.14.0\n",
            "    Uninstalling h11-0.14.0:\n",
            "      Successfully uninstalled h11-0.14.0\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.7\n",
            "    Uninstalling idna-3.7:\n",
            "      Successfully uninstalled idna-3.7\n",
            "  Attempting uninstall: httpcore\n",
            "    Found existing installation: httpcore 1.0.5\n",
            "    Uninstalling httpcore-1.0.5:\n",
            "      Successfully uninstalled httpcore-1.0.5\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.27.0\n",
            "    Uninstalling httpx-0.27.0:\n",
            "      Successfully uninstalled httpx-0.27.0\n",
            "Successfully installed chardet-3.0.4 googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2024.5.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\n",
            "Requirement already satisfied: googletrans==4.0.0-rc1 in /usr/local/lib/python3.10/dist-packages (4.0.0rc1)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.10/dist-packages (from googletrans==4.0.0-rc1) (0.13.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2024.2.2)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2024.5.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.1)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2.10)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.5.0)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.1)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.0)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.2.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.7)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.40.2)\n",
            "Collecting transformers[torch]\n",
            "  Downloading transformers-4.41.0-py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.14.0)\n",
            "Collecting huggingface-hub<1.0,>=0.23.0 (from transformers[torch])\n",
            "  Downloading huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.2/401.2 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.2.1+cu121)\n",
            "Collecting accelerate>=0.21.0 (from transformers[torch])\n",
            "  Downloading accelerate-0.30.1-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.4.127)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
            "Installing collected packages: huggingface-hub, transformers, accelerate\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.20.3\n",
            "    Uninstalling huggingface-hub-0.20.3:\n",
            "      Successfully uninstalled huggingface-hub-0.20.3\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.40.2\n",
            "    Uninstalling transformers-4.40.2:\n",
            "      Successfully uninstalled transformers-4.40.2\n",
            "Successfully installed accelerate-0.30.1 huggingface-hub-0.23.0 transformers-4.41.0\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-24.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "Successfully installed pip-24.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Collecting torch\n",
            "  Downloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Collecting triton==2.3.0 (from torch)\n",
            "  Downloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Downloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nccl-cu12, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.2.0\n",
            "    Uninstalling triton-2.2.0:\n",
            "      Successfully uninstalled triton-2.2.0\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.19.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.19.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.19.3\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.2.1+cu121\n",
            "    Uninstalling torch-2.2.1+cu121:\n",
            "      Successfully uninstalled torch-2.2.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 2.3.0 which is incompatible.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 2.3.0 which is incompatible.\n",
            "torchvision 0.17.1+cu121 requires torch==2.2.1, but you have torch 2.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-nccl-cu12-2.20.5 torch-2.3.0 triton-2.3.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.0)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import re\n",
        "import googletrans\n",
        "from googletrans import Translator\n",
        "import json\n",
        "import openai\n",
        "\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import accelerate\n",
        "print(accelerate.__version__)  # This will print the version of the accelerate library\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from transformers import GPT2Tokenizer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import pandas as pd\n",
        "from io import BytesIO\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nVodh40AjQ-m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe364dc3-67b1-4686-b80b-00f6eaca0a80"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.30.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load_thirukkural_data(file_path):\n",
        "    \"\"\"Load Thirukkural data from a JSON file.\"\"\"\n",
        "    with open(file_path, 'r') as file:\n",
        "        return json.load(file)\n",
        "\n",
        "kural_data = load_thirukkural_data(\"/content/drive/MyDrive/THIRUKURAL/thirukural_git.json\")"
      ],
      "metadata": {
        "id": "HazC8pljE8AN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the function to get responses based on Thirukkural\n",
        "\n",
        "\n",
        "def get_thirukkural_response(kural_data, query_type, query_value, translate_to=None, author_alias=None, detail=None):\n",
        "    \"\"\"Retrieve a Thirukkural response based on query type, value, and optional author explanation.\"\"\"\n",
        "    translator = googletrans.Translator()\n",
        "    responses = []\n",
        "    author_map = {\n",
        "        'mu_va': 'ta_mu_va',\n",
        "        'mu va': 'ta_mu_va',\n",
        "        'ta_mu_va': 'ta_mu_va',\n",
        "        'salamon': 'ta_salamon',\n",
        "        'ta_salamon': 'ta_salamon',\n",
        "        'சாலமன் பாப்பையா': 'ta_salamon'\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def translate(text, target_lang):\n",
        "        \"\"\"Helper function to translate text using Google Translate.\"\"\"\n",
        "        if target_lang == 'en':\n",
        "            return translator.translate(text, src='ta', dest='en').text\n",
        "        elif target_lang == 'ta':\n",
        "            return translator.translate(text, src='en', dest='ta').text\n",
        "        return text\n",
        "\n",
        "    # Process queries based on type\n",
        "    kurals_to_process = []\n",
        "    if query_type == 'kural_number':\n",
        "        kural = next((k for k in kural_data['kurals'] if k['number'] == int(query_value)), None)\n",
        "        if kural:\n",
        "            kurals_to_process.append(kural)\n",
        "    elif query_type in ['keyword', 'chapter_name', 'section_name']:\n",
        "        if query_type == 'keyword':\n",
        "            kurals_to_process = [k for k in kural_data['kurals'] if query_value.lower() in \" \".join(k['kural']).lower()]\n",
        "        elif query_type == 'chapter_name':\n",
        "            kurals_to_process = [k for k in kural_data['kurals'] if k['chapter'].lower() == query_value.lower()]\n",
        "        elif query_type == 'section_name':\n",
        "            kurals_to_process = [k for k in kural_data['kurals'] if k['section'].lower() == query_value.lower()]\n",
        "\n",
        "    # Generate responses for each kural\n",
        "    for kural in kurals_to_process:\n",
        "        kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "        if translate_to == 'ta':\n",
        "            english_meaning = kural['meaning'].get('en', \"No English translation available.\")\n",
        "            translated_text = translate(english_meaning, 'ta')\n",
        "            responses.append(f\"{kural_text}\\nMeaning (Tamil): {translated_text}\")\n",
        "        elif author_alias and author_alias in ['mu_va', 'salamon']:\n",
        "            author_key = 'ta_' + author_alias if 'ta_' not in author_alias else author_alias\n",
        "            explanation = kural['meaning'].get(author_key, \"No explanation available.\")\n",
        "            translated_text = translate(explanation, 'en')\n",
        "            responses.append(f\"{kural_text}\\nExplanation by {author_alias} (English): {translated_text}\")\n",
        "        else:\n",
        "            english_meaning = kural['meaning'].get('en', \"No English translation available.\")\n",
        "            responses.append(f\"{kural_text}\\nMeaning (English): {english_meaning}\")\n",
        "\n",
        "    return \"\\n\".join(responses) if responses else \"No Kural found matching the query.\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # # Helper function to perform translation\n",
        "    # def translate(text, target_lang):\n",
        "    #     \"\"\"Translate text using Google Translate.\"\"\"\n",
        "    #     if target_lang:\n",
        "    #         try:\n",
        "    #             return translator.translate(text, src='ta' if target_lang == 'en' else 'en', dest=target_lang).text\n",
        "    #         except Exception as e:\n",
        "    #             print(f\"Translation failed: {e}\")\n",
        "    #             return text\n",
        "    #     return text\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Identify kurals based on query_type\n",
        "    kurals_to_process = []\n",
        "    if query_type == 'section_name':\n",
        "        kurals_to_process = [k for k in kural_data['kurals'] if k['section'] == query_value]\n",
        "    elif query_type == 'chapter_name':\n",
        "        kurals_to_process = [k for k in kural_data['kurals'] if k['chapter'] == query_value]\n",
        "    elif query_type in ['keyword', 'starts_with', 'ends_with']:\n",
        "        for kural in kural_data['kurals']:\n",
        "            if (query_type == 'keyword' and query_value in ' '.join(kural['kural']).lower()) or \\\n",
        "               (query_type == 'starts_with' and kural['kural'][0].startswith(query_value)) or \\\n",
        "               (query_type == 'ends_with' and kural['kural'][-1].endswith(query_value)):\n",
        "                kurals_to_process.append(kural)\n",
        "\n",
        "    # Generate responses for each kural\n",
        "    for kural in kurals_to_process:\n",
        "        kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "        if translate_to == 'ta':\n",
        "            english_meaning = kural['meaning'].get('en', \"No English translation available.\")\n",
        "            translated_text = translate(english_meaning, 'en', 'ta')\n",
        "            responses.append(f\"{kural_text}\\nMeaning (Tamil): {translated_text}\")\n",
        "        elif author_alias and author_alias in author_map:\n",
        "            author_key = author_map[author_alias]\n",
        "            explanation = kural['meaning'].get(author_key, \"No explanation available.\")\n",
        "            if translate_to == 'en':\n",
        "                translated_text = translate(explanation, 'ta', 'en')\n",
        "                responses.append(f\"{kural_text}\\nExplanation by {author_alias} (English): {translated_text}\")\n",
        "            else:\n",
        "                responses.append(f\"{kural_text}\\nExplanation by {author_alias}: {explanation}\")\n",
        "        else:\n",
        "            english_meaning = kural['meaning'].get('en', \"No English translation available.\")\n",
        "            responses.append(f\"{kural_text}\\nMeaning (English): {english_meaning}\")\n",
        "\n",
        "\n",
        "\n",
        "    # Define a function to format the response for kurals\n",
        "    def format_kural_response(kural):\n",
        "        \"\"\"Format the response for a single kural with optional translation or explanation.\"\"\"\n",
        "        kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "        if author_alias and author_alias in author_map:\n",
        "            author_key = author_map[author_alias]\n",
        "            explanation = kural['meaning'].get(author_key, \"No explanation available.\")\n",
        "            if translate_to:\n",
        "                explanation = translate(explanation, translate_to)\n",
        "            response = f\"{kural_text}\\nExplanation by {author_key.replace('ta_', '')}: {explanation}\"\n",
        "        elif translate_to:\n",
        "            english_meaning = kural['meaning'].get('en', \"No English translation available.\")\n",
        "            translated_meaning = translate(english_meaning, translate_to)\n",
        "            response = f\"{kural_text}\\nMeaning ({translate_to.capitalize()}): {translated_meaning}\"\n",
        "        else:\n",
        "            english_meaning = kural['meaning'].get('en', \"No English translation available.\")\n",
        "            response = f\"{kural_text}\\nMeaning (English): {english_meaning}\"\n",
        "        return response\n",
        "\n",
        "\n",
        "        # Rule 1 & 2: Section and/or Chapter based queries\n",
        "    if query_type in ['section_name', 'chapter_name']:\n",
        "        for kural in kural_data['kurals']:\n",
        "            if (query_type == 'section_name' and kural['section'] == query_value) or \\\n",
        "               (query_type == 'chapter_name' and kural['chapter'] == query_value):\n",
        "                kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "                if author_alias and author_alias in author_map:\n",
        "                    author_key = author_map[author_alias]\n",
        "                    explanation = kural['meaning'].get(author_key, \"No explanation available.\")\n",
        "                    kural_text += f\"\\nExplanation by {author_key}: {explanation}\"\n",
        "                else:\n",
        "                    kural_text += f\"\\nMeaning (English): {kural['meaning']['en']}\"\n",
        "                responses.append(kural_text)\n",
        "\n",
        "    # Rule 3, 9: Keyword based English meanings\n",
        "    if query_type == 'keyword':\n",
        "        kurals_by_keyword = [kural for kural in kural_data['kurals'] if query_value in ' '.join(kural['kural']).lower()]\n",
        "        if detail == 'english_meaning':\n",
        "            responses.extend([f\"Kural {k['number']}: {' '.join(k['kural'])}\\nMeaning (English): {k['meaning']['en']}\" for k in kurals_by_keyword])\n",
        "        elif detail == 'chapter_list':\n",
        "            chapters = set(k['chapter'] for k in kurals_by_keyword)\n",
        "            responses.extend(list(chapters))\n",
        "        else:\n",
        "            for kural in kurals_by_keyword:\n",
        "                if author_alias in author_map:\n",
        "                    kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "                    author_key = author_map[author_alias]\n",
        "                    explanation = kural['meaning'].get(author_key, \"No explanation available.\")\n",
        "                    responses.append(f\"{kural_text}\\nExplanation by {author_key}: {explanation}\")\n",
        "\n",
        "    # Rule 7, 8, 13, 14: Kurals starting/ending with a specific word\n",
        "    if query_type == 'starts_with':\n",
        "        responses.extend([f\"Kural {k['number']}: {' '.join(k['kural'])}\" for k in kural_data['kurals'] if k['kural'][0].startswith(query_value)])\n",
        "    if query_type == 'ends_with':\n",
        "        responses.extend([f\"Kural {k['number']}: {' '.join(k['kural'])}\" for k in kural_data['kurals'] if k['kural'][-1].endswith(query_value)])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Fetch by kural number\n",
        "    if query_type == 'kural_number':\n",
        "        kural_match = next((k for k in kural_data['kurals'] if k['number'] == int(query_value)), None)\n",
        "        if kural_match:\n",
        "            kural_text = f\"Kural {kural_match['number']}: {' '.join(kural_match['kural'])}\"\n",
        "            if author_alias and author_alias in author_map:\n",
        "                author_key = author_map[author_alias]\n",
        "                author_explanation = kural_match['meaning'].get(author_key, \"No explanation available for this author.\")\n",
        "                responses.append(f\"{kural_text}\\nExplanation by {author_key.replace('ta_', '')}: {author_explanation}\")\n",
        "            else:\n",
        "                english_meaning = kural_match['meaning'].get('en', \"No English translation available.\")\n",
        "                responses.append(f\"{kural_text}\\nMeaning (English): {english_meaning}\")\n",
        "\n",
        "    # Fetch by chapter name\n",
        "    elif query_type == 'chapter_name':\n",
        "        kurals_in_chapter = [k for k in kural_data['kurals'] if k['chapter'].lower() == query_value.lower()]\n",
        "        for kural in kurals_in_chapter:\n",
        "            kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "            if author_alias and author_alias in author_map:\n",
        "                author_key = author_map[author_alias]\n",
        "                explanation = kural['meaning'].get(author_key, \"No explanation available.\")\n",
        "                responses.append(f\"{kural_text}\\nExplanation by {author_key.replace('ta_', '')}: {explanation}\")\n",
        "            else:\n",
        "                english_meaning = kural['meaning'].get('en', \"No English translation available.\")\n",
        "                responses.append(f\"{kural_text}\\nMeaning (English): {english_meaning}\")\n",
        "\n",
        "    # Fetch by section name\n",
        "    elif query_type == 'section_name':\n",
        "        chapters_in_section = set(k['chapter'] for k in kural_data['kurals'] if k['section'].lower() == query_value.lower())\n",
        "        for chapter in chapters_in_section:\n",
        "            kurals_in_chapter = [k for k in kural_data['kurals'] if k['chapter'].lower() == chapter.lower()]\n",
        "            chapter_responses = []\n",
        "            for kural in kurals_in_chapter:\n",
        "                kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "                english_meaning = kural['meaning'].get('en', \"No English translation available.\")\n",
        "                chapter_responses.append(f\"{kural_text}\\nMeaning (English): {english_meaning}\")\n",
        "            responses.append(f\"Chapter: {chapter}\\n\" + \"\\n\".join(chapter_responses))\n",
        "\n",
        "\n",
        "                # Fetch by keyword in kural, which checks for keywords in the text of the kural\n",
        "    elif query_type == 'keyword':\n",
        "        kurals_by_keyword = [kural for kural in kural_data['kurals'] if query_value in \" \".join(kural['kural']).lower()]\n",
        "        for kural in kurals_by_keyword:\n",
        "            kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "            if author_alias and author_alias in author_map:\n",
        "                author_key = author_map[author_alias]\n",
        "                explanation = kural['meaning'].get(author_key, \"No explanation available.\")\n",
        "                responses.append(f\"{kural_text}\\nExplanation by {author_key.replace('ta_', '')}: {explanation}\")\n",
        "            else:\n",
        "                english_meaning = kural['meaning'].get('en', \"No English translation available.\")\n",
        "                responses.append(f\"{kural_text}\\nMeaning (English): {english_meaning}\")\n",
        "\n",
        "\n",
        "# Logic to handle different types of queries\n",
        "    elif query_type == 'keyword':\n",
        "        if detail == 'starts_with':\n",
        "            kurals_filtered = [kural for kural in kural_data['kurals'] if kural['kural'][0].startswith(query_value)]\n",
        "        elif detail == 'ends_with':\n",
        "            kurals_filtered = [kural for kural in kural_data['kurals'] if kural['kural'][-1].endswith(query_value)]\n",
        "        for kural in kurals_filtered:\n",
        "            kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "            responses.append(kural_text)\n",
        "\n",
        "    elif query_type == 'author_translation':\n",
        "        kurals_filtered = [kural for kural in kural_data['kurals'] if author_alias in kural['meaning']]\n",
        "        for kural in kurals_filtered:\n",
        "            explanation = kural['meaning'][author_alias]\n",
        "            kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\\nExplanation by {author_alias}: {explanation}\"\n",
        "            responses.append(kural_text)\n",
        "\n",
        "    elif query_type == 'chapter_count':\n",
        "        count = sum(1 for kural in kural_data['kurals'] if kural['chapter'] == query_value)\n",
        "        responses.append(f\"Total kurals in chapter '{query_value}': {count}\")\n",
        "\n",
        "    # Check for the correct handling of the 'author_translation' query type\n",
        "    elif query_type == 'author_translation':\n",
        "        # Assuming query_value should be something like 'ta_mu_va'\n",
        "        kurals_filtered = [kural for kural in kural_data['kurals'] if query_value in kural['meaning']]\n",
        "        for kural in kurals_filtered:\n",
        "            explanation = kural['meaning'].get(query_value)\n",
        "            if explanation:  # Ensure there's a translation available\n",
        "                kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\\nExplanation by {query_value}: {explanation}\"\n",
        "                responses.append(kural_text)\n",
        "\n",
        "\n",
        "\n",
        "    # Fetch kurals that start or end with a specific word\n",
        "    elif query_type == 'starts_with' or query_type == 'ends_with':\n",
        "        kurals_filtered = [\n",
        "            kural for kural in kural_data['kurals']\n",
        "            if (query_type == 'starts_with' and kural['kural'][0].startswith(query_value)) or\n",
        "               (query_type == 'ends_with' and kural['kural'][1].endswith(query_value))\n",
        "        ]\n",
        "        for kural in kurals_filtered:\n",
        "            kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "            english_meaning = kural['meaning'].get('en', \"No English translation available.\")\n",
        "            responses.append(f\"{kural_text}\\nMeaning (English): {english_meaning}\")\n",
        "\n",
        "            # Fetch kurals containing a keyword with different requirements\n",
        "    elif query_type == 'keyword':\n",
        "        filtered_kurals = [kural for kural in kural_data['kurals'] if query_value in \" \".join(kural['kural']).lower()]\n",
        "        if detail == 'chapter_list':\n",
        "            # List chapters that contain the keyword\n",
        "            chapter_set = set(kural['chapter'] for kural in filtered_kurals)\n",
        "            responses = list(chapter_set)\n",
        "        elif detail in ['mu_va', 'ta_salamon']:\n",
        "            # Show kural and explanation by the specific author for the keyword\n",
        "            for kural in filtered_kurals:\n",
        "                kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "                author_explanation = kural['meaning'].get(detail, \"No explanation available.\")\n",
        "                responses.append(f\"{kural_text}\\nExplanation by {detail}: {author_explanation}\")\n",
        "        elif detail == 'starts_with':\n",
        "            # Kurals that start with the specific word\n",
        "            responses = [f\"Kural {k['number']}: {' '.join(k['kural'])}\" for k in filtered_kurals if k['kural'][0].startswith(query_value)]\n",
        "        elif detail == 'ends_with':\n",
        "            # Kurals that end with the specific word\n",
        "            responses = [f\"Kural {k['number']}: {' '.join(k['kural'])}\" for k in filtered_kurals if k['kural'][1].endswith(query_value)]\n",
        "        else:\n",
        "            # Default to showing English translation only\n",
        "            for kural in filtered_kurals:\n",
        "                kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "                english_meaning = kural['meaning'].get('en', \"No English translation available.\")\n",
        "                responses.append(f\"{kural_text}\\nMeaning (English): {english_meaning}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return \"\\n\".join(responses) if responses else \"No Kural found matching the query.\"\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YwW0WiOoEsHf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Questions for test"
      ],
      "metadata": {
        "id": "rm2MT55PxCWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Translate English meanings to Tamil for kural number 1\n",
        "# print(get_thirukkural_response(kural_data, 'kural_number', '1', translate_to='ta'))\n",
        "\n",
        "# # Translate MuVa's explanation for kural number 1 into English\n",
        "# print(get_thirukkural_response(kural_data, 'kural_number', '1', translate_to='en', author_alias='mu_va'))\n",
        "\n",
        "# # Show direct English translation for kural number 1\n",
        "# print(get_thirukkural_response(kural_data, 'chapter', '1'))\n",
        "# # # Example usage of the function\n",
        "# query_type = 'kural_number'\n",
        "# query_value = 90  # Kural number to fetch\n",
        "# response = get_thirukkural_response(kural_data, query_type, query_value)\n",
        "# print(response)\n",
        "\n",
        "# # # # Test fetching a kural by number with explanations from specific authors\n",
        "# print(get_thirukkural_response(kural_data, 'kural_number', '7', author_alias='mu_va'))  # Mu Va's explanation\n",
        "# print(get_thirukkural_response(kural_data, 'kural_number', '10', author_alias='salamon'))  # Salamon's explanation\n",
        "# # # # Test fetching a kural by number with no specific author explanation\n",
        "# print(get_thirukkural_response(kural_data, 'kural_number', '1'))\n",
        "\n",
        "\n",
        "# # # # Query all chapters within a section, showing only English translations\n",
        "# print(get_thirukkural_response(kural_data, 'section_name', 'அறத்துப்பால்'))\n",
        "# # # # Fetching all kurals in a specific chapter and showing explanations from 'Mu Va'\n",
        "# print(get_thirukkural_response(kural_data, 'chapter_name', 'கடவுள் வாழ்த்து', author_alias='mu_va'))\n",
        "# # # Fetch chapters containing the word 'கேடு'\n",
        "#print(get_thirukkural_response(kural_data, 'keyword', 'கேடு', detail='chapter_list'))\n",
        "# print(get_thirukkural_response(kural_data, 'kural_number', '1', 'author_translation', 'ta_mu_va'))  # All kurals with 'ta_mu_va' translation\n",
        "# # # Fetch kurals with explanation by 'mu_va' for the keyword 'கேடு'\n",
        "# # print(get_thirukkural_response(kural_data, 'keyword', 'கேடு', author_alias='mu_va'))\n",
        "\n",
        "# # # Fetch kurals starting with 'அகர'\n",
        "# # print(get_thirukkural_response(kural_data, 'keyword', 'அகர', detail='starts_with'))\n",
        "\n",
        "# # # # Fetch kurals ending with 'உலகு'\n",
        "# # print(get_thirukkural_response(kural_data, 'keyword', 'உலகு', detail='ends_with'))\n",
        "# print(get_thirukkural_response(kural_data, 'kural_number', 1, 'mu va'))\n",
        "# #print(get_thirukkural_response(kural_data, 'kural_number', 1, 'salamon'))\n",
        "# # print(get_thirukkural_response(kural_data, 'kural_number', 1))\n",
        "\n",
        "# # Assuming kural_data is structured with 'chapters' as strings and 'kurals' as detailed objects\n",
        "\n",
        "# # Query a specific chapter with a request for an explanation from 'Mu Va'\n",
        "# # print(get_thirukkural_response(kural_data, 'chapter_name', 'கடவுள் வாழ்த்து', 'mu va'))\n",
        "\n",
        "# # Query all chapters within a section, only showing English translations\n",
        "# # print(get_thirukkural_response(kural_data, 'section_name', 'அறத்துப்பால்'))\n",
        "# # print(get_thirukkural_response(kural_data, 'chapter_name', 'கடவுள் வாழ்த்து'))  # All kurals in the chapter \"கடவுள் வாழ்த்து\"\n",
        "# # print(get_thirukkural_response(kural_data, 'keyword', 'உலகு'))           # Search by keyword in kurals\n",
        "# # Fetch all kurals containing the word 'கேடு' with English translation\n",
        "# # print(get_thirukkural_response(kural_data, 'keyword', 'கேடு'))\n",
        "# # # Fetch chapters containing the word 'கேடு'\n",
        "# # print(get_thirukkural_response(kural_data, 'keyword', 'கேடு', 'chapter_list'))\n",
        "# # # Fetch kurals starting with 'அகர'\n",
        "# # print(get_thirukkural_response(kural_data, 'keyword', 'அகர', 'starts_with'))\n",
        "\n",
        "# # # Fetch kurals ending with 'உலகு'\n",
        "# # print(get_thirukkural_response(kural_data, 'keyword', 'உலகு', 'ends_with'))\n",
        "\n",
        "# # # Fetch kurals with explanation by 'mu_va' for the keyword 'கேடு'\n",
        "# # print(get_thirukkural_response(kural_data, 'keyword', 'கேடு', 'mu_va'))\n",
        "\n",
        "# # print(get_thirukkural_response(kural_data, 'chapter_count', 'கடவுள் வாழ்த்து'))  # Count kurals in chapter\n",
        "\n",
        "\n",
        "\n",
        "# # print(get_thirukkural_response(kural_data, 'section_name', 'அறத்துப்பால்'))\n",
        "# # print(get_thirukkural_response(kural_data, 'chapter_name', 'கடவுள் வாழ்த்து', 'mu va'))\n",
        "# # print(get_thirukkural_response(kural_data, 'chapter_name', 'கடவுள் வாழ்த்து'))\n",
        "\n",
        "\n",
        "# # print(get_thirukkural_response(kural_data, 'section_name', 'அறத்துப்பால்', 'mu_va'))\n",
        "\n",
        "\n",
        "# # # Assuming kural_data is structured with 'chapters' as strings and 'kurals' as detailed objects\n",
        "\n",
        "# # print(get_thirukkural_response(kural_data, 'kural_number', 1, translate_to='en', author_alias='mu_va'))\n",
        "# # # Translate English meanings to Tamil for kural number 1\n",
        "# # print(get_thirukkural_response(kural_data, 'kural_number', '1', translate_to='ta'))\n",
        "\n",
        "# # # Translate MuVa's explanation for kural number 1 into English\n",
        "# print(get_thirukkural_response(kural_data, 'kural_number', '1', translate_to='en', author_alias='mu_va'))\n",
        "\n",
        "# # # Show direct English translation for kural number 1\n",
        "# # print(get_thirukkural_response(kural_data, 'chapter', '1'))\n",
        "\n",
        "\n",
        "\n",
        "# # # # Count of kurals in a specific chapter\n",
        "# # print(get_thirukkural_response(kural_data, 'chapter_count', 'கடவுள் வாழ்த்து'))\n",
        "\n",
        "# # # # Assuming kural_data is structured with 'chapters' as strings and 'kurals' as detailed objects\n",
        "\n",
        "# print(get_thirukkural_response(kural_data, 'kural_number', 1, translate_to='en', author_alias='mu_va'))\n",
        "# # # # Translate English meanings to Tamil for kural number 1\n",
        "# print(get_thirukkural_response(kural_data, 'kural_number', '1', translate_to='ta'))"
      ],
      "metadata": {
        "id": "nr7VY43UHVll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATA FOR GPT2"
      ],
      "metadata": {
        "id": "UrcCQQWHWTgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Updated and complete answers\n",
        "answers = [\n",
        "    \"The opening verse praises the Almighty, highlighting the primacy of rain sourced from the waters governed by the divine. It sets the thematic tone of the text, emphasizing moral and ethical living under divine guidance, foundational in Tamil literature.\",\n",
        "    \"This verse suggests that a leader should not just plan but foresee outcomes and act accordingly, emphasizing proactive leadership.\",\n",
        "    \"It describes rain as the linchpin of the natural world and human civilization, essential for agriculture and life, advocating for environmental stewardship.\",\n",
        "    \"It extols the virtues of truthfulness and moral integrity above all else, stressing core Tamil cultural values of ethical living and honesty.\",\n",
        "    \"Discusses moderation in life and using resources wisely, echoing today’s global calls for sustainability and environmental conservation.\",\n",
        "    \"Highlights the importance of choosing friends who are virtuous and wise, advising to choose friends who uplift morally and intellectually.\",\n",
        "    \"Advises rulers to be just and ethical to ensure their reign is respected and enduring, emphasizing good governance based on ethical conduct and justice.\",\n",
        "    \"Emphasizes the role of justice as foundational to societal structure and leadership, advocating for fairness and righteousness in governance and daily life.\",\n",
        "    \"Celebrates the virtues of being a gracious host, depicting hospitality as a moral obligation and a sign of good character.\",\n",
        "    \"Elevates patience as a virtue that underpins effective problem-solving and peace, crucial for personal and social harmony.\",\n",
        "    \"Stresses the importance of learning from the wise, advocating for humility and the continuous pursuit of knowledge.\",\n",
        "    \"Warns about the destructive nature of anger, depicting it as a potent force that can ruin relationships and personal peace.\",\n",
        "    \"Advocates for self-restraint and control over one's desires, portraying self-discipline as essential for ethical living and spiritual growth.\",\n",
        "    \"Highlights the importance of expressing gratitude, enriching one's life and strengthening community bonds.\",\n",
        "    \"Advocates for truth as a fundamental moral value, essential for trust and integrity in personal and public spheres.\",\n",
        "    \"Discusses the negative impacts of greed, leading to moral and sometimes material ruin.\",\n",
        "    \"Discusses the virtues of benevolence and altruism, encouraging actions that promote the welfare of others as a foundation for a virtuous life.\",\n",
        "    \"Explores the concept of karma, or actions and their results, emphasizing moral responsibility and the ethical consequences of one's actions.\",\n",
        "    \"Underlines the ethical responsibilities of leaders towards their subjects, portraying leadership as not just a position but a moral duty to act for the common good.\",\n",
        "    \"Offers advice on prudent financial management and the dangers of mismanagement, stressing the balance between earning, saving, and spending wisely.\",\n",
        "    \"Links the acquisition of wealth to virtuous living, teaching that true wealth comes from living virtuously and using resources ethically.\",\n",
        "    \"Advocates for perseverance in the face of adversity, key to overcoming challenges and achieving goals.\",\n",
        "    \"Offers guidance on resilience and mental strength, stressing the importance of inner fortitude in navigating life's challenges.\",\n",
        "    \"Discusses ethical dilemmas and the importance of moral decision-making, central to personal integrity and societal respect.\",\n",
        "    \"Provides insights on resolving conflicts through diplomacy and understanding, advocating for peaceful resolution and understanding in conflicts.\"\n",
        "]\n",
        "# Completing the DataFrame creation by providing all necessary components including questions, answers, and verse numbers.\n",
        "\n",
        "\n",
        "\n",
        "# List of verse numbers\n",
        "verse_numbers = [\n",
        "    1, 5, 15, 25, 37, 45, 60, 75, 85, 90, 101, 110, 125, 135, 145, 150, 165, 175, 180, 190, 200, 210, 220, 230, 240\n",
        "]\n",
        "\n",
        "# List of questions\n",
        "questions = [\n",
        "    \"What is the meaning of Thirukkural verse 1 and its significance in Tamil literature?\",\n",
        "    \"How does verse 5 of the Thirukkural address the concept of leadership?\",\n",
        "    \"In what context does Thirukkural verse 15 discuss the importance of rain?\",\n",
        "    \"What moral values are emphasized in verse 25 of the Thirukkural?\",\n",
        "    \"How does verse 37 relate to the contemporary idea of sustainable living?\",\n",
        "    \"What advice does Thiruvalluvar offer about friendship in verse 45?\",\n",
        "    \"Discuss the implications of verse 60 on the conduct of a ruler.\",\n",
        "    \"How does verse 75 of the Thirukkural address the theme of justice?\",\n",
        "    \"What are the virtues extolled in verse 85 concerning hospitality?\",\n",
        "    \"How is the virtue of patience depicted in verse 90 of the Thirukkural?\",\n",
        "    \"Interpret the meaning behind the advice given in verse 101.\",\n",
        "    \"Explain how verse 110 discusses the repercussions of anger.\",\n",
        "    \"What insights does verse 125 provide on the importance of self-discipline?\",\n",
        "    \"Discuss the role of gratitude as depicted in verse 135 of the Thirukkural.\",\n",
        "    \"How does verse 145 advocate for truthfulness?\",\n",
        "    \"What does verse 150 say about the consequences of greed?\",\n",
        "    \"Explain the philosophical underpinnings of verse 165 in the Thirukkural.\",\n",
        "    \"How does verse 175 enhance our understanding of karma?\",\n",
        "    \"What lesson on leadership can be drawn from verse 180?\",\n",
        "    \"Analyze the advice on wealth management given in verse 190 of the Thirukkural.\",\n",
        "    \"What does verse 200 teach us about the balance between wealth and virtue?\",\n",
        "    \"How does verse 210 address the theme of determination?\",\n",
        "    \"Interpret the guidance provided in verse 220 on dealing with adversity.\",\n",
        "    \"What ethical considerations are highlighted in verse 230?\",\n",
        "    \"How does verse 240 of the Thirukkural relate to modern concepts of conflict resolution?\"\n",
        "]\n",
        "\n",
        "# Labels corresponding to each question\n",
        "labels = [\n",
        "    \"Meaning and Significance\", \"Leadership\", \"Importance of Rain\", \"Moral Values\",\n",
        "    \"Sustainable Living\", \"Friendship\", \"Ruler Conduct\", \"Justice\", \"Hospitality\",\n",
        "    \"Patience\", \"Advice Interpretation\", \"Repercussions of Anger\", \"Self-discipline\",\n",
        "    \"Gratitude\", \"Truthfulness\", \"Greed Consequences\", \"Philosophical Underpinnings\",\n",
        "    \"Karma\", \"Leadership\", \"Wealth Management\", \"Wealth and Virtue\", \"Determination\",\n",
        "    \"Dealing with Adversity\", \"Ethical Considerations\", \"Conflict Resolution\"\n",
        "]\n",
        "\n",
        "# Assembling the DataFrame\n",
        "dataframe = pd.DataFrame({\n",
        "    \"Verse Number\": verse_numbers,\n",
        "    \"Question\": questions,\n",
        "    \"Label\": labels,\n",
        "    \"Answer\": answers\n",
        "})\n",
        "\n",
        "dataframe"
      ],
      "metadata": {
        "id": "O7Gvp1PImjaY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "0684c6c7-8e1e-4af4-9f1f-d71d5123549f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Verse Number                                           Question  \\\n",
              "0              1  What is the meaning of Thirukkural verse 1 and...   \n",
              "1              5  How does verse 5 of the Thirukkural address th...   \n",
              "2             15  In what context does Thirukkural verse 15 disc...   \n",
              "3             25  What moral values are emphasized in verse 25 o...   \n",
              "4             37  How does verse 37 relate to the contemporary i...   \n",
              "5             45  What advice does Thiruvalluvar offer about fri...   \n",
              "6             60  Discuss the implications of verse 60 on the co...   \n",
              "7             75  How does verse 75 of the Thirukkural address t...   \n",
              "8             85  What are the virtues extolled in verse 85 conc...   \n",
              "9             90  How is the virtue of patience depicted in vers...   \n",
              "10           101  Interpret the meaning behind the advice given ...   \n",
              "11           110  Explain how verse 110 discusses the repercussi...   \n",
              "12           125  What insights does verse 125 provide on the im...   \n",
              "13           135  Discuss the role of gratitude as depicted in v...   \n",
              "14           145      How does verse 145 advocate for truthfulness?   \n",
              "15           150  What does verse 150 say about the consequences...   \n",
              "16           165  Explain the philosophical underpinnings of ver...   \n",
              "17           175  How does verse 175 enhance our understanding o...   \n",
              "18           180  What lesson on leadership can be drawn from ve...   \n",
              "19           190  Analyze the advice on wealth management given ...   \n",
              "20           200  What does verse 200 teach us about the balance...   \n",
              "21           210  How does verse 210 address the theme of determ...   \n",
              "22           220  Interpret the guidance provided in verse 220 o...   \n",
              "23           230  What ethical considerations are highlighted in...   \n",
              "24           240  How does verse 240 of the Thirukkural relate t...   \n",
              "\n",
              "                          Label  \\\n",
              "0      Meaning and Significance   \n",
              "1                    Leadership   \n",
              "2            Importance of Rain   \n",
              "3                  Moral Values   \n",
              "4            Sustainable Living   \n",
              "5                    Friendship   \n",
              "6                 Ruler Conduct   \n",
              "7                       Justice   \n",
              "8                   Hospitality   \n",
              "9                      Patience   \n",
              "10        Advice Interpretation   \n",
              "11       Repercussions of Anger   \n",
              "12              Self-discipline   \n",
              "13                    Gratitude   \n",
              "14                 Truthfulness   \n",
              "15           Greed Consequences   \n",
              "16  Philosophical Underpinnings   \n",
              "17                        Karma   \n",
              "18                   Leadership   \n",
              "19            Wealth Management   \n",
              "20            Wealth and Virtue   \n",
              "21                Determination   \n",
              "22       Dealing with Adversity   \n",
              "23       Ethical Considerations   \n",
              "24          Conflict Resolution   \n",
              "\n",
              "                                               Answer  \n",
              "0   The opening verse praises the Almighty, highli...  \n",
              "1   This verse suggests that a leader should not j...  \n",
              "2   It describes rain as the linchpin of the natur...  \n",
              "3   It extols the virtues of truthfulness and mora...  \n",
              "4   Discusses moderation in life and using resourc...  \n",
              "5   Highlights the importance of choosing friends ...  \n",
              "6   Advises rulers to be just and ethical to ensur...  \n",
              "7   Emphasizes the role of justice as foundational...  \n",
              "8   Celebrates the virtues of being a gracious hos...  \n",
              "9   Elevates patience as a virtue that underpins e...  \n",
              "10  Stresses the importance of learning from the w...  \n",
              "11  Warns about the destructive nature of anger, d...  \n",
              "12  Advocates for self-restraint and control over ...  \n",
              "13  Highlights the importance of expressing gratit...  \n",
              "14  Advocates for truth as a fundamental moral val...  \n",
              "15  Discusses the negative impacts of greed, leadi...  \n",
              "16  Discusses the virtues of benevolence and altru...  \n",
              "17  Explores the concept of karma, or actions and ...  \n",
              "18  Underlines the ethical responsibilities of lea...  \n",
              "19  Offers advice on prudent financial management ...  \n",
              "20  Links the acquisition of wealth to virtuous li...  \n",
              "21  Advocates for perseverance in the face of adve...  \n",
              "22  Offers guidance on resilience and mental stren...  \n",
              "23  Discusses ethical dilemmas and the importance ...  \n",
              "24  Provides insights on resolving conflicts throu...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-00e185f9-c80e-4c36-9719-d00bf90393fc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Verse Number</th>\n",
              "      <th>Question</th>\n",
              "      <th>Label</th>\n",
              "      <th>Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>What is the meaning of Thirukkural verse 1 and...</td>\n",
              "      <td>Meaning and Significance</td>\n",
              "      <td>The opening verse praises the Almighty, highli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>How does verse 5 of the Thirukkural address th...</td>\n",
              "      <td>Leadership</td>\n",
              "      <td>This verse suggests that a leader should not j...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15</td>\n",
              "      <td>In what context does Thirukkural verse 15 disc...</td>\n",
              "      <td>Importance of Rain</td>\n",
              "      <td>It describes rain as the linchpin of the natur...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>25</td>\n",
              "      <td>What moral values are emphasized in verse 25 o...</td>\n",
              "      <td>Moral Values</td>\n",
              "      <td>It extols the virtues of truthfulness and mora...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>37</td>\n",
              "      <td>How does verse 37 relate to the contemporary i...</td>\n",
              "      <td>Sustainable Living</td>\n",
              "      <td>Discusses moderation in life and using resourc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>45</td>\n",
              "      <td>What advice does Thiruvalluvar offer about fri...</td>\n",
              "      <td>Friendship</td>\n",
              "      <td>Highlights the importance of choosing friends ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>60</td>\n",
              "      <td>Discuss the implications of verse 60 on the co...</td>\n",
              "      <td>Ruler Conduct</td>\n",
              "      <td>Advises rulers to be just and ethical to ensur...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>75</td>\n",
              "      <td>How does verse 75 of the Thirukkural address t...</td>\n",
              "      <td>Justice</td>\n",
              "      <td>Emphasizes the role of justice as foundational...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>85</td>\n",
              "      <td>What are the virtues extolled in verse 85 conc...</td>\n",
              "      <td>Hospitality</td>\n",
              "      <td>Celebrates the virtues of being a gracious hos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>90</td>\n",
              "      <td>How is the virtue of patience depicted in vers...</td>\n",
              "      <td>Patience</td>\n",
              "      <td>Elevates patience as a virtue that underpins e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>101</td>\n",
              "      <td>Interpret the meaning behind the advice given ...</td>\n",
              "      <td>Advice Interpretation</td>\n",
              "      <td>Stresses the importance of learning from the w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>110</td>\n",
              "      <td>Explain how verse 110 discusses the repercussi...</td>\n",
              "      <td>Repercussions of Anger</td>\n",
              "      <td>Warns about the destructive nature of anger, d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>125</td>\n",
              "      <td>What insights does verse 125 provide on the im...</td>\n",
              "      <td>Self-discipline</td>\n",
              "      <td>Advocates for self-restraint and control over ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>135</td>\n",
              "      <td>Discuss the role of gratitude as depicted in v...</td>\n",
              "      <td>Gratitude</td>\n",
              "      <td>Highlights the importance of expressing gratit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>145</td>\n",
              "      <td>How does verse 145 advocate for truthfulness?</td>\n",
              "      <td>Truthfulness</td>\n",
              "      <td>Advocates for truth as a fundamental moral val...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>150</td>\n",
              "      <td>What does verse 150 say about the consequences...</td>\n",
              "      <td>Greed Consequences</td>\n",
              "      <td>Discusses the negative impacts of greed, leadi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>165</td>\n",
              "      <td>Explain the philosophical underpinnings of ver...</td>\n",
              "      <td>Philosophical Underpinnings</td>\n",
              "      <td>Discusses the virtues of benevolence and altru...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>175</td>\n",
              "      <td>How does verse 175 enhance our understanding o...</td>\n",
              "      <td>Karma</td>\n",
              "      <td>Explores the concept of karma, or actions and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>180</td>\n",
              "      <td>What lesson on leadership can be drawn from ve...</td>\n",
              "      <td>Leadership</td>\n",
              "      <td>Underlines the ethical responsibilities of lea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>190</td>\n",
              "      <td>Analyze the advice on wealth management given ...</td>\n",
              "      <td>Wealth Management</td>\n",
              "      <td>Offers advice on prudent financial management ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>200</td>\n",
              "      <td>What does verse 200 teach us about the balance...</td>\n",
              "      <td>Wealth and Virtue</td>\n",
              "      <td>Links the acquisition of wealth to virtuous li...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>210</td>\n",
              "      <td>How does verse 210 address the theme of determ...</td>\n",
              "      <td>Determination</td>\n",
              "      <td>Advocates for perseverance in the face of adve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>220</td>\n",
              "      <td>Interpret the guidance provided in verse 220 o...</td>\n",
              "      <td>Dealing with Adversity</td>\n",
              "      <td>Offers guidance on resilience and mental stren...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>230</td>\n",
              "      <td>What ethical considerations are highlighted in...</td>\n",
              "      <td>Ethical Considerations</td>\n",
              "      <td>Discusses ethical dilemmas and the importance ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>240</td>\n",
              "      <td>How does verse 240 of the Thirukkural relate t...</td>\n",
              "      <td>Conflict Resolution</td>\n",
              "      <td>Provides insights on resolving conflicts throu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-00e185f9-c80e-4c36-9719-d00bf90393fc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-00e185f9-c80e-4c36-9719-d00bf90393fc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-00e185f9-c80e-4c36-9719-d00bf90393fc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-283cf7cc-8736-478c-9211-4a0fa87048e3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-283cf7cc-8736-478c-9211-4a0fa87048e3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-283cf7cc-8736-478c-9211-4a0fa87048e3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataframe",
              "summary": "{\n  \"name\": \"dataframe\",\n  \"rows\": 25,\n  \"fields\": [\n    {\n      \"column\": \"Verse Number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 74,\n        \"min\": 1,\n        \"max\": 240,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          85,\n          165,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"What are the virtues extolled in verse 85 concerning hospitality?\",\n          \"Explain the philosophical underpinnings of verse 165 in the Thirukkural.\",\n          \"What is the meaning of Thirukkural verse 1 and its significance in Tamil literature?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24,\n        \"samples\": [\n          \"Hospitality\",\n          \"Philosophical Underpinnings\",\n          \"Meaning and Significance\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"Celebrates the virtues of being a gracious host, depicting hospitality as a moral obligation and a sign of good character.\",\n          \"Discusses the virtues of benevolence and altruism, encouraging actions that promote the welfare of others as a foundation for a virtuous life.\",\n          \"The opening verse praises the Almighty, highlighting the primacy of rain sourced from the waters governed by the divine. It sets the thematic tone of the text, emphasizing moral and ethical living under divine guidance, foundational in Tamil literature.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Formatting the Data"
      ],
      "metadata": {
        "id": "aAKBEnU7yDru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "formatted_data = []\n",
        "for question, answer in zip(questions, answers):\n",
        "    # Combine question and answer with special tokens\n",
        "    formatted_entry = f\"{question} <|answer|> {answer} <|endoftext|>\"\n",
        "    formatted_data.append(formatted_entry)\n"
      ],
      "metadata": {
        "id": "MxuiTPV0yIFl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Tokenizing the Data"
      ],
      "metadata": {
        "id": "iqh-oE_2yPQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "\n",
        "# Tokenize the formatted data\n",
        "tokenized_data = [tokenizer.encode(data_entry, add_special_tokens=True) for data_entry in formatted_data]\n"
      ],
      "metadata": {
        "id": "Uxrq2lGKyMQO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232,
          "referenced_widgets": [
            "989b76d0cbe24d4e9c805b6da99a0b52",
            "2146741e877d466c820145df94100d7d",
            "3da41766198749bcb6412701fa373481",
            "348856135a374947920447478288b3b0",
            "b8558ea56e624e879b6401b1c01b0cc1",
            "7dc836e861bf437b8ae3f532b8e89210",
            "d8760320c31e4abf892d96286105758c",
            "0906d3cde1074ca98a0224a34defae2c",
            "3b8a64ee528b466f909b9f385ab8e3e5",
            "0a6492b0a6714af7bf6512c448eb1b22",
            "df1b4cb675ac4c65ac2fce5a80d33233",
            "b8b984a2c19e4bb0ad996d095f125c13",
            "5806094ee27640d293a0686b864216d7",
            "13ccf522d7e1493fb69f0fb2b8f61df6",
            "d161afe13774417b8f2126fce830a9ad",
            "de2d50cf4eaa4cf7bd0f59e42c6021c6",
            "ba0617194ec441f285f2c9fe72b9da33",
            "c2c027ffb8614cc6be60c9de448505a2",
            "f5f8339972d04e7abebaea8428d8aaeb",
            "9210a0d0f15b4d3e985d4bb8d843c577",
            "d69e4dc12d334839bf27ffb58c6421e2",
            "0d7cd8a72d1f40d3ad9d0b1b831a493b",
            "67a24b00b41b494c859fb1a83190a9a7",
            "b2432f7336024892a5f7789cab0bef63",
            "935b42ff162d4620aadef9e6c63bb87f",
            "a378f7980f634ffbae752a6f8a2640ea",
            "763b778cb85046528e73ab1ac0f58eb4",
            "c16a6ebbfd8145f3b8aa501084251332",
            "ddf07a831d1d4057a796f41edbf85538",
            "a58c0f389fa7476c99867371e92f3b2f",
            "47da4329829141ffa163d79a7244c9c1",
            "6e9cad36a3fc4e2d9448738035656c47",
            "3e5f582f0a6f46e79689f8d5c2fc605d",
            "5ce7d08003a84e469bc9e9c882af88b7",
            "633b1d57eb9f470a83361f2d2b3cf3fe",
            "59cfd2a418a3461c83a5c225448b97d6",
            "38605d6089f94c70aa5a06a3db311edc",
            "e97b574ee9be4ac1813d5f689eb1a56a",
            "286aceae1c294f8cad379fa65b6608c5",
            "a8b011b875aa4c8bb6a0919b48339098",
            "dc5305d13483401f861d6c5d2ebd7c3d",
            "07557da5c9f449349a1287c9fa91dc36",
            "5e996324dac94aa8b006b88dafb9abb2",
            "752ee8d07b374cc696636bc8a24c3db1",
            "602b748598c44c3c9af66b3b2d9c9137",
            "a7deec7fd5b44b87b3d7d8b0842770b3",
            "cb04739c6a8346a1b1441abc2d414418",
            "5d267d5c594f42d6b4729f3bdf2ba0ea",
            "938a5d59cb7d41c7866c854bc61bd8c5",
            "8138458bdc104a1eb885fc8bdc46b64b",
            "6b20164464904dea8f704f176617bbd1",
            "e466f635986c4621bff414b74962763b",
            "1a8beb54a49646108522eddb27f1cc13",
            "112b9a7040464accae51635a0367b88a",
            "01d7ebd0f14b4004a9b3bbc16da08746"
          ]
        },
        "outputId": "c4c1e867-636b-4cce-9f58-020a2a91ea0a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "989b76d0cbe24d4e9c805b6da99a0b52"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8b984a2c19e4bb0ad996d095f125c13"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67a24b00b41b494c859fb1a83190a9a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ce7d08003a84e469bc9e9c882af88b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "602b748598c44c3c9af66b3b2d9c9137"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Creating a Custom Dataset"
      ],
      "metadata": {
        "id": "388gcLvRyiTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize the tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "\n",
        "# Since GPT-2 does not have a pad token by default, we can use eos_token as the pad token.\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "\n",
        "# Function to tokenize and pad texts\n",
        "def tokenize_and_pad(text_list, max_length):\n",
        "    encodings = tokenizer(text_list, add_special_tokens=True, truncation=True, padding='max_length', max_length=max_length, return_tensors=\"pt\")\n",
        "    # Shift input_ids to the right to create labels\n",
        "    encodings['labels'] = encodings.input_ids.detach().clone()\n",
        "    return encodings\n",
        "\n",
        "\n",
        "# Create a dataset class for handling the encoded data\n",
        "class ThirukkuralDataset(Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Retrieve input_ids for the sample\n",
        "        input_ids = self.encodings['input_ids'][idx]\n",
        "        # Labels are usually shifted input_ids for language modeling\n",
        "        labels = input_ids.clone()  # Make a copy of input_ids to use as labels\n",
        "        return {'input_ids': input_ids, 'labels': labels, 'attention_mask': self.encodings['attention_mask'][idx]}\n",
        "\n",
        "\n",
        "\n",
        "# Prepare data for tokenizer\n",
        "formatted_data = [f\"{question} <|answer|> {answer} <|endoftext|>\" for question, answer in zip(questions, answers)]\n",
        "\n",
        "# Tokenize and pad the data\n",
        "encoded_inputs = tokenize_and_pad(formatted_data, max_length=512)  # Adjust max_length as needed\n",
        "\n",
        "# Create the dataset\n",
        "dataset = ThirukkuralDataset(encoded_inputs)\n",
        "\n",
        "# Setup DataLoader\n",
        "batch_size = 4\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Example usage of the DataLoader\n",
        "for batch in dataloader:\n",
        "    print(batch['input_ids'].shape)\n",
        "    print(batch['labels'].shape)  # Ensure labels are being correctly formed\n",
        "    print(batch['attention_mask'].shape)\n",
        "    break  # Break after printing the first batch\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6HDEURzz3W4",
        "outputId": "b6e1ee1d-c545-41c3-af36-6f7615ab8510"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 512])\n",
            "torch.Size([4, 512])\n",
            "torch.Size([4, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Assuming 'encoded_inputs' is your full dataset containing keys like 'input_ids' and 'attention_mask'\n",
        "input_ids_train, input_ids_val, attention_mask_train, attention_mask_val = train_test_split(\n",
        "    encoded_inputs['input_ids'], encoded_inputs['attention_mask'], test_size=0.1, random_state=42\n",
        ")\n",
        "\n",
        "# Reconstruct the train and validation sets\n",
        "train_encodings = {'input_ids': input_ids_train, 'attention_mask': attention_mask_train}\n",
        "val_encodings = {'input_ids': input_ids_val, 'attention_mask': attention_mask_val}\n",
        "\n",
        "# Now, wrap these in your dataset class\n",
        "train_dataset = ThirukkuralDataset(train_encodings)\n",
        "val_dataset = ThirukkuralDataset(val_encodings)\n"
      ],
      "metadata": {
        "id": "bfwYt_3rEDQc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, Trainer, TrainingArguments\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "# Load a pre-trained GPT-2 model\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # Output directory for model checkpoints\n",
        "    evaluation_strategy=\"epoch\",     # Evaluation is done at the end of each epoch\n",
        "    learning_rate=1e-5,              # Learning rate\n",
        "    per_device_train_batch_size=4,   # Batch size per device during training\n",
        "    per_device_eval_batch_size=4,    # Batch size per device during evaluation\n",
        "    num_train_epochs=4,              # Number of training epochs\n",
        "    weight_decay=0.1,               # Weight decay if applicable\n",
        "    logging_dir='./logs',            # Directory for storing logs\n",
        "    logging_steps=30,                # Log metrics every 10 steps\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Initialize the Trainer with both training and validation datasets\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset  # Include the validation dataset here\n",
        ")\n",
        "\n",
        "# Start training\n",
        "trainer.train()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354,
          "referenced_widgets": [
            "f07c0790e5ed4f0688741545dd5e1675",
            "cfb32e18f3ae4bec81e4581f4af4f9e7",
            "7c9605515a43412692a3f0a677cc4de4",
            "45f88df21bc8414e91e11dde8f9dfc2f",
            "5828ec60aed34f0cba1d250e10120b40",
            "6f043fe4f70148868109c35446921e48",
            "30a27c4c5d8a454790c54819e3bfc880",
            "aca48123cfd042a9a26029a1387126b8",
            "e17ca888e2eb4816af606de6e405ea45",
            "4432cd47213d41cfb1b5e9b302505509",
            "5c857b7b17684c8b98ef9e520b1ed7b6",
            "7ce85e9ebcd1422f9ec5f4525d222912",
            "7deb9579bcc14a90b31fb1c17e4fdf85",
            "fa74c420613b43e4b79d26dfc596969e",
            "78a198008a034ce391e0d8164f2cc55b",
            "1cad3648357849a3b81477b2a8a1dd71",
            "6287d1cf42cd4f98b877eb0e42d694dd",
            "c7e10139ee9a49e5aebc8e074ad7b88c",
            "d18e2a8c837a43f8a271b6bdc8fa85f4",
            "8b8a268f5bb347fbb153169c3d73269e",
            "dc5e555eeba04e22802e15dbbf7a152d",
            "b15015a191614bb38adb921f5fa07d31"
          ]
        },
        "id": "_jhHlcBd23Ir",
        "outputId": "5efdb20d-b778-4bcd-f95c-b71fb1fecc56"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f07c0790e5ed4f0688741545dd5e1675"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ce85e9ebcd1422f9ec5f4525d222912"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [24/24 00:12, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>7.264630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.316241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.804288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.340427</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=24, training_loss=5.223552068074544, metrics={'train_runtime': 14.3331, 'train_samples_per_second': 6.14, 'train_steps_per_second': 1.674, 'total_flos': 22993698816000.0, 'train_loss': 5.223552068074544, 'epoch': 4.0})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Predictions"
      ],
      "metadata": {
        "id": "0kQbdb64GsNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)  # Make sure to move your model to the same device!\n"
      ],
      "metadata": {
        "id": "6PWYuOaMK2RE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bf4e713-e9c9-4efa-db48-62ac36dd74a8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Assuming 'val_dataset' is already created and is available\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=16)\n",
        "\n",
        "model.eval()  # Set model to evaluation mode\n",
        "predictions = []\n",
        "labels = []\n",
        "\n",
        "for batch in val_dataloader:\n",
        "    input_ids = batch['input_ids'].to(device)\n",
        "    attention_mask = batch['attention_mask'].to(device)\n",
        "    labels += batch['labels'].tolist()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        preds = torch.argmax(outputs.logits, dim=-1).cpu().numpy()\n",
        "        predictions.extend(preds)\n",
        "\n",
        "# Flatten lists if predictions and labels are not flat (depends on model and data)\n",
        "predictions = [p for sublist in predictions for p in sublist]\n",
        "labels = [l for sublist in labels for l in sublist]\n"
      ],
      "metadata": {
        "id": "ag5LcMB5GheE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Convert class weights from dictionary values to a list\n",
        "# class_weights_list = list(class_weights_dict.values())\n",
        "\n",
        "# # Convert the list to a tensor\n",
        "# class_weights_tensor = torch.tensor(class_weights_list, dtype=torch.float).to(device)\n",
        "\n",
        "# # Use this tensor in the loss function (if using CrossEntropyLoss for classification)\n",
        "# loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights_tensor)\n"
      ],
      "metadata": {
        "id": "NPIBZubENE-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Assuming 'labels' is a list of all your labels\n",
        "# classes = np.unique(labels)  # Extract unique classes\n",
        "\n",
        "# # Compute class weights for these unique classes\n",
        "# class_weights = compute_class_weight('balanced', classes=classes, y=labels)\n",
        "\n",
        "# # Create a dictionary mapping class index to weight\n",
        "# class_weights_dict = {classes[i]: class_weights[i] for i in range(len(classes))}\n",
        "\n",
        "# # If you have non-sequential class labels, make sure they match with your model's output layer\n"
      ],
      "metadata": {
        "id": "GsJtOGgoNKxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compute Precision, Recall, and F1-Score"
      ],
      "metadata": {
        "id": "4oW8kU1nLBqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "print(\"Label distribution in predictions:\", Counter(predictions))\n",
        "print(\"Label distribution in true labels:\", Counter(labels))\n"
      ],
      "metadata": {
        "id": "M6Z3FQ8cL2Ku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e53f00ed-6f46-4a62-f9cc-53d3f9159fbd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label distribution in predictions: Counter({198: 1108, 464: 170, 50256: 102, 262: 29, 286: 12, 290: 12, 13: 12, 29: 8, 30: 4, 318: 3, 257: 3, 922: 3, 1266: 2, 416: 2, 1279: 2, 1849: 2, 20283: 2, 3099: 2, 3616: 2, 284: 2, 4453: 2, 383: 2, 692: 1, 276: 1, 642: 1, 378: 1, 27494: 1, 33362: 1, 2583: 1, 11: 1, 355: 1, 1611: 1, 481: 1, 3450: 1, 79: 1, 3732: 1, 654: 1, 1708: 1, 343: 1, 71: 1, 17580: 1, 10396: 1, 594: 1, 1042: 1, 326: 1, 389: 1, 9490: 1, 880: 1, 1724: 1, 329: 1, 1365: 1, 1204: 1, 27193: 1, 849: 1, 338: 1, 25: 1, 362: 1, 46917: 1, 536: 1, 366: 1, 1793: 1, 1109: 1, 1590: 1, 422: 1, 3800: 1, 1512: 1, 4732: 1, 1621: 1, 8557: 1, 3815: 1, 11154: 1, 3968: 1})\n",
            "Label distribution in true labels: Counter({50256: 1370, 262: 13, 286: 8, 91: 6, 257: 5, 11: 5, 13: 5, 287: 4, 18527: 4, 290: 4, 27494: 3, 1279: 3, 41484: 3, 29: 3, 220: 3, 2061: 2, 33362: 2, 30: 2, 355: 2, 6573: 2, 739: 2, 536: 2, 343: 2, 2724: 2, 74: 2, 1523: 2, 32519: 2, 9285: 2, 11871: 2, 389: 1, 1070: 1, 692: 1, 276: 1, 7600: 1, 9305: 1, 28921: 1, 689: 1, 852: 1, 43210: 1, 2583: 1, 27561: 1, 12990: 1, 1051: 1, 922: 1, 2095: 1, 18438: 1, 391: 1, 17580: 1, 79: 1, 3732: 1, 654: 1, 21409: 1, 36691: 1, 274: 1, 10004: 1, 10396: 1, 594: 1, 37677: 1, 1042: 1, 12577: 1, 4028: 1, 326: 1, 7719: 1, 9490: 1, 1854: 1, 8489: 1, 329: 1, 41276: 1, 1204: 1, 318: 1, 3616: 1, 352: 1, 663: 1, 12085: 1, 383: 1, 4756: 1, 40221: 1, 33987: 1, 21292: 1, 2684: 1, 1590: 1, 6290: 1, 18229: 1, 422: 1, 10150: 1, 21825: 1, 416: 1, 632: 1, 5621: 1, 606: 1, 1512: 1, 8216: 1, 2420: 1, 36360: 1, 15028: 1, 2877: 1, 11154: 1, 43936: 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "precision = precision_score(labels, predictions, average='macro')\n",
        "recall = recall_score(labels, predictions, average='macro')\n",
        "f1 = f1_score(labels, predictions, average='macro')\n",
        "\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-Score: {f1}\")\n"
      ],
      "metadata": {
        "id": "g5l3uTKyLEYy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31224fa6-2711-48e4-f573-92c92f018ef2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.007633587786259542\n",
            "Recall: 0.0005683401125536301\n",
            "F1-Score: 0.0010579156986392298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained('./my_trained_model')\n"
      ],
      "metadata": {
        "id": "HLmhOqLPNcdy"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# QUERY DETAILS GPT2"
      ],
      "metadata": {
        "id": "q3DwrcYLVQ1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def extract_query_details(query):\n",
        "    query = query.lower()\n",
        "    details = {\n",
        "        'query_type': None,\n",
        "        'query_value': None,\n",
        "        'translate_to': 'en' if 'in english' in query else None,\n",
        "        'author_alias': None,\n",
        "        'detail': None\n",
        "    }\n",
        "\n",
        "    # Adjusting to match the structure needed to extract the kural number\n",
        "    match = re.search(r'kural number (\\d+)', query)\n",
        "    if match:\n",
        "        details['query_type'] = 'kural_number'\n",
        "        details['query_value'] = int(match.group(1))\n",
        "\n",
        "    return details\n",
        "\n",
        "\n",
        "\n",
        "    # Define the Thirukkural response function\n",
        "     # Define the function to get responses based on Thirukkural\n",
        "\n",
        "\n",
        "def get_thirukkural_response(kural_data, query_type, query_value, translate_to=None, author_alias=None, detail=None):\n",
        "    \"\"\"Retrieve a Thirukkural response based on query type, value, and optional author explanation.\"\"\"\n",
        "    translator = googletrans.Translator()\n",
        "    responses = []\n",
        "    author_map = {\n",
        "        'mu_va': 'ta_mu_va',\n",
        "        'mu va': 'ta_mu_va',\n",
        "        'ta_mu_va': 'ta_mu_va',\n",
        "        'salamon': 'ta_salamon',\n",
        "        'ta_salamon': 'ta_salamon',\n",
        "        'சாலமன் பாப்பையா': 'ta_salamon'\n",
        "    }\n",
        "\n",
        "\n",
        "    # Helper function to perform translation\n",
        "    def translate(text, target_lang):\n",
        "        \"\"\"Translate text using Google Translate.\"\"\"\n",
        "        if target_lang:\n",
        "            try:\n",
        "                return translator.translate(text, src='ta' if target_lang == 'en' else 'en', dest=target_lang).text\n",
        "            except Exception as e:\n",
        "                print(f\"Translation failed: {e}\")\n",
        "                return text\n",
        "        return text\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Identify kurals based on query_type\n",
        "    kurals_to_process = []\n",
        "    if query_type == 'section_name':\n",
        "        kurals_to_process = [k for k in kural_data['kurals'] if k['section'] == query_value]\n",
        "    elif query_type == 'chapter_name':\n",
        "        kurals_to_process = [k for k in kural_data['kurals'] if k['chapter'] == query_value]\n",
        "    elif query_type in ['keyword', 'starts_with', 'ends_with']:\n",
        "        for kural in kural_data['kurals']:\n",
        "            if (query_type == 'keyword' and query_value in ' '.join(kural['kural']).lower()) or \\\n",
        "               (query_type == 'starts_with' and kural['kural'][0].startswith(query_value)) or \\\n",
        "               (query_type == 'ends_with' and kural['kural'][-1].endswith(query_value)):\n",
        "                kurals_to_process.append(kural)\n",
        "\n",
        "    # Generate responses for each kural\n",
        "    for kural in kurals_to_process:\n",
        "        kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "        if translate_to == 'ta':\n",
        "            english_meaning = kural['meaning'].get('en', \"No English translation available.\")\n",
        "            translated_text = translate(english_meaning, 'en', 'ta')\n",
        "            responses.append(f\"{kural_text}\\nMeaning (Tamil): {translated_text}\")\n",
        "        elif author_alias and author_alias in author_map:\n",
        "            author_key = author_map[author_alias]\n",
        "            explanation = kural['meaning'].get(author_key, \"No explanation available.\")\n",
        "            if translate_to == 'en':\n",
        "                translated_text = translate(explanation, 'ta', 'en')\n",
        "                responses.append(f\"{kural_text}\\nExplanation by {author_alias} (English): {translated_text}\")\n",
        "            else:\n",
        "                responses.append(f\"{kural_text}\\nExplanation by {author_alias}: {explanation}\")\n",
        "        else:\n",
        "            english_meaning = kural['meaning'].get('en', \"No English translation available.\")\n",
        "            responses.append(f\"{kural_text}\\nMeaning (English): {english_meaning}\")\n",
        "\n",
        "\n",
        "\n",
        "    # Define a function to format the response for kurals\n",
        "    def format_kural_response(kural):\n",
        "        \"\"\"Format the response for a single kural with optional translation or explanation.\"\"\"\n",
        "        kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "        if author_alias and author_alias in author_map:\n",
        "            author_key = author_map[author_alias]\n",
        "            explanation = kural['meaning'].get(author_key, \"No explanation available.\")\n",
        "            if translate_to:\n",
        "                explanation = translate(explanation, translate_to)\n",
        "            response = f\"{kural_text}\\nExplanation by {author_key.replace('ta_', '')}: {explanation}\"\n",
        "        elif translate_to:\n",
        "            english_meaning = kural['meaning'].get('en', \"No English translation available.\")\n",
        "            translated_meaning = translate(english_meaning, translate_to)\n",
        "            response = f\"{kural_text}\\nMeaning ({translate_to.capitalize()}): {translated_meaning}\"\n",
        "        else:\n",
        "            english_meaning = kural['meaning'].get('en', \"No English translation available.\")\n",
        "            response = f\"{kural_text}\\nMeaning (English): {english_meaning}\"\n",
        "        return response\n",
        "\n",
        "\n",
        "        # Rule 1 & 2: Section and/or Chapter based queries\n",
        "    if query_type in ['section_name', 'chapter_name']:\n",
        "        for kural in kural_data['kurals']:\n",
        "            if (query_type == 'section_name' and kural['section'] == query_value) or \\\n",
        "               (query_type == 'chapter_name' and kural['chapter'] == query_value):\n",
        "                kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "                if author_alias and author_alias in author_map:\n",
        "                    author_key = author_map[author_alias]\n",
        "                    explanation = kural['meaning'].get(author_key, \"No explanation available.\")\n",
        "                    kural_text += f\"\\nExplanation by {author_key}: {explanation}\"\n",
        "                else:\n",
        "                    kural_text += f\"\\nMeaning (English): {kural['meaning']['en']}\"\n",
        "                responses.append(kural_text)\n",
        "\n",
        "    # Rule 3, 9: Keyword based English meanings\n",
        "    if query_type == 'keyword':\n",
        "        kurals_by_keyword = [kural for kural in kural_data['kurals'] if query_value in ' '.join(kural['kural']).lower()]\n",
        "        if detail == 'english_meaning':\n",
        "            responses.extend([f\"Kural {k['number']}: {' '.join(k['kural'])}\\nMeaning (English): {k['meaning']['en']}\" for k in kurals_by_keyword])\n",
        "        elif detail == 'chapter_list':\n",
        "            chapters = set(k['chapter'] for k in kurals_by_keyword)\n",
        "            responses.extend(list(chapters))\n",
        "        else:\n",
        "            for kural in kurals_by_keyword:\n",
        "                if author_alias in author_map:\n",
        "                    kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "                    author_key = author_map[author_alias]\n",
        "                    explanation = kural['meaning'].get(author_key, \"No explanation available.\")\n",
        "                    responses.append(f\"{kural_text}\\nExplanation by {author_key}: {explanation}\")\n",
        "\n",
        "    # Rule 7, 8, 13, 14: Kurals starting/ending with a specific word\n",
        "    if query_type == 'starts_with':\n",
        "        responses.extend([f\"Kural {k['number']}: {' '.join(k['kural'])}\" for k in kural_data['kurals'] if k['kural'][0].startswith(query_value)])\n",
        "    if query_type == 'ends_with':\n",
        "        responses.extend([f\"Kural {k['number']}: {' '.join(k['kural'])}\" for k in kural_data['kurals'] if k['kural'][-1].endswith(query_value)])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Fetch by kural number\n",
        "    if query_type == 'kural_number':\n",
        "        kural_match = next((k for k in kural_data['kurals'] if k['number'] == int(query_value)), None)\n",
        "        if kural_match:\n",
        "            kural_text = f\"Kural {kural_match['number']}: {' '.join(kural_match['kural'])}\"\n",
        "            if author_alias and author_alias in author_map:\n",
        "                author_key = author_map[author_alias]\n",
        "                author_explanation = kural_match['meaning'].get(author_key, \"No explanation available for this author.\")\n",
        "                responses.append(f\"{kural_text}\\nExplanation by {author_key.replace('ta_', '')}: {author_explanation}\")\n",
        "            else:\n",
        "                english_meaning = kural_match['meaning'].get('en', \"No English translation available.\")\n",
        "                responses.append(f\"{kural_text}\\nMeaning (English): {english_meaning}\")\n",
        "\n",
        "    # Fetch by chapter name\n",
        "    elif query_type == 'chapter_name':\n",
        "        kurals_in_chapter = [k for k in kural_data['kurals'] if k['chapter'].lower() == query_value.lower()]\n",
        "        for kural in kurals_in_chapter:\n",
        "            kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "            if author_alias and author_alias in author_map:\n",
        "                author_key = author_map[author_alias]\n",
        "                explanation = kural['meaning'].get(author_key, \"No explanation available.\")\n",
        "                responses.append(f\"{kural_text}\\nExplanation by {author_key.replace('ta_', '')}: {explanation}\")\n",
        "            else:\n",
        "                english_meaning = kural['meaning'].get('en', \"No English translation available.\")\n",
        "                responses.append(f\"{kural_text}\\nMeaning (English): {english_meaning}\")\n",
        "\n",
        "    # Fetch by section name\n",
        "    elif query_type == 'section_name':\n",
        "        chapters_in_section = set(k['chapter'] for k in kural_data['kurals'] if k['section'].lower() == query_value.lower())\n",
        "        for chapter in chapters_in_section:\n",
        "            kurals_in_chapter = [k for k in kural_data['kurals'] if k['chapter'].lower() == chapter.lower()]\n",
        "            chapter_responses = []\n",
        "            for kural in kurals_in_chapter:\n",
        "                kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "                english_meaning = kural['meaning'].get('en', \"No English translation available.\")\n",
        "                chapter_responses.append(f\"{kural_text}\\nMeaning (English): {english_meaning}\")\n",
        "            responses.append(f\"Chapter: {chapter}\\n\" + \"\\n\".join(chapter_responses))\n",
        "\n",
        "\n",
        "                # Fetch by keyword in kural, which checks for keywords in the text of the kural\n",
        "    elif query_type == 'keyword':\n",
        "        kurals_by_keyword = [kural for kural in kural_data['kurals'] if query_value in \" \".join(kural['kural']).lower()]\n",
        "        for kural in kurals_by_keyword:\n",
        "            kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "            if author_alias and author_alias in author_map:\n",
        "                author_key = author_map[author_alias]\n",
        "                explanation = kural['meaning'].get(author_key, \"No explanation available.\")\n",
        "                responses.append(f\"{kural_text}\\nExplanation by {author_key.replace('ta_', '')}: {explanation}\")\n",
        "            else:\n",
        "                english_meaning = kural['meaning'].get('en', \"No English translation available.\")\n",
        "                responses.append(f\"{kural_text}\\nMeaning (English): {english_meaning}\")\n",
        "\n",
        "\n",
        "# Logic to handle different types of queries\n",
        "    elif query_type == 'keyword':\n",
        "        if detail == 'starts_with':\n",
        "            kurals_filtered = [kural for kural in kural_data['kurals'] if kural['kural'][0].startswith(query_value)]\n",
        "        elif detail == 'ends_with':\n",
        "            kurals_filtered = [kural for kural in kural_data['kurals'] if kural['kural'][-1].endswith(query_value)]\n",
        "        for kural in kurals_filtered:\n",
        "            kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "            responses.append(kural_text)\n",
        "\n",
        "    elif query_type == 'author_translation':\n",
        "        kurals_filtered = [kural for kural in kural_data['kurals'] if author_alias in kural['meaning']]\n",
        "        for kural in kurals_filtered:\n",
        "            explanation = kural['meaning'][author_alias]\n",
        "            kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\\nExplanation by {author_alias}: {explanation}\"\n",
        "            responses.append(kural_text)\n",
        "\n",
        "    elif query_type == 'chapter_count':\n",
        "        count = sum(1 for kural in kural_data['kurals'] if kural['chapter'] == query_value)\n",
        "        responses.append(f\"Total kurals in chapter '{query_value}': {count}\")\n",
        "\n",
        "    # Check for the correct handling of the 'author_translation' query type\n",
        "    elif query_type == 'author_translation':\n",
        "        # Assuming query_value should be something like 'ta_mu_va'\n",
        "        kurals_filtered = [kural for kural in kural_data['kurals'] if query_value in kural['meaning']]\n",
        "        for kural in kurals_filtered:\n",
        "            explanation = kural['meaning'].get(query_value)\n",
        "            if explanation:  # Ensure there's a translation available\n",
        "                kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\\nExplanation by {query_value}: {explanation}\"\n",
        "                responses.append(kural_text)\n",
        "\n",
        "\n",
        "\n",
        "    # Fetch kurals that start or end with a specific word\n",
        "    elif query_type == 'starts_with' or query_type == 'ends_with':\n",
        "        kurals_filtered = [\n",
        "            kural for kural in kural_data['kurals']\n",
        "            if (query_type == 'starts_with' and kural['kural'][0].startswith(query_value)) or\n",
        "               (query_type == 'ends_with' and kural['kural'][1].endswith(query_value))\n",
        "        ]\n",
        "        for kural in kurals_filtered:\n",
        "            kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "            english_meaning = kural['meaning'].get('en', \"No English translation available.\")\n",
        "            responses.append(f\"{kural_text}\\nMeaning (English): {english_meaning}\")\n",
        "\n",
        "            # Fetch kurals containing a keyword with different requirements\n",
        "    elif query_type == 'keyword':\n",
        "        filtered_kurals = [kural for kural in kural_data['kurals'] if query_value in \" \".join(kural['kural']).lower()]\n",
        "        if detail == 'chapter_list':\n",
        "            # List chapters that contain the keyword\n",
        "            chapter_set = set(kural['chapter'] for kural in filtered_kurals)\n",
        "            responses = list(chapter_set)\n",
        "        elif detail in ['mu_va', 'ta_salamon']:\n",
        "            # Show kural and explanation by the specific author for the keyword\n",
        "            for kural in filtered_kurals:\n",
        "                kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "                author_explanation = kural['meaning'].get(detail, \"No explanation available.\")\n",
        "                responses.append(f\"{kural_text}\\nExplanation by {detail}: {author_explanation}\")\n",
        "        elif detail == 'starts_with':\n",
        "            # Kurals that start with the specific word\n",
        "            responses = [f\"Kural {k['number']}: {' '.join(k['kural'])}\" for k in filtered_kurals if k['kural'][0].startswith(query_value)]\n",
        "        elif detail == 'ends_with':\n",
        "            # Kurals that end with the specific word\n",
        "            responses = [f\"Kural {k['number']}: {' '.join(k['kural'])}\" for k in filtered_kurals if k['kural'][1].endswith(query_value)]\n",
        "        else:\n",
        "            # Default to showing English translation only\n",
        "            for kural in filtered_kurals:\n",
        "                kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "                english_meaning = kural['meaning'].get('en', \"No English translation available.\")\n",
        "                responses.append(f\"{kural_text}\\nMeaning (English): {english_meaning}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return \"\\n\".join(responses) if responses else \"No Kural found matching the query.\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Call the response function with the extracted details\n",
        "    return get_thirukkural_response(**details)\n",
        "\n",
        "# Load the JSON file\n",
        "with open(\"/content/drive/MyDrive/THIRUKURAL/thirukural_git.json\", \"r\") as file:\n",
        "    kural_data = json.load(file)\n",
        "\n",
        "# Example usage\n",
        "query = \"What is the meaning of Kural number 5 in English?\"\n",
        "details = extract_query_details(query)\n",
        "response = get_thirukkural_response(kural_data, **details)\n",
        "print(response)\n"
      ],
      "metadata": {
        "id": "Miug2Ccdjo-Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7de7ea29-d57d-4d79-fc61-b8b181820e87"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kural 5: இருள்சேர் இருவினையும் சேரா இறைவன் பொருள்சேர் புகழ்புரிந்தார் மாட்டு.\n",
            "Meaning (English): The two-fold deeds that spring from darkness shall not adhere to those who delight in the true praise of God.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dispatcher Fuction GPT2"
      ],
      "metadata": {
        "id": "kvWXTfIf7h2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Assuming the functions get_thirukkural_response and extract_query_details are defined as before\n",
        "\n",
        "def dispatcher(query, kural_data):\n",
        "    details = extract_query_details(query)\n",
        "\n",
        "    # Rule-based criteria: If the query details extracted match specific types that the rule-based system can handle\n",
        "    if details['query_type'] in ['kural_number', 'section_name', 'chapter_name']:\n",
        "        return get_thirukkural_response(kural_data, **details)\n",
        "    else:\n",
        "        # If the query doesn't fit the rule-based system or requires more sophisticated understanding\n",
        "        return handle_ai_based(query)\n",
        "\n",
        "\n",
        "def handle_ai_based(query):\n",
        "    # Load the model and tokenizer\n",
        "    model = GPT2LMHeadModel.from_pretrained('./my_trained_model')\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "\n",
        "    # Set padding token and adjust padding side for decoder-only architectures\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    tokenizer.padding_side = 'left'\n",
        "\n",
        "    # Encode the inputs\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        query,\n",
        "        return_tensors=\"pt\",\n",
        "        add_special_tokens=True,\n",
        "        max_length=50,\n",
        "        padding='max_length',\n",
        "        truncation=True\n",
        "    )\n",
        "\n",
        "    # Generate response using adjusted generation settings\n",
        "    outputs = model.generate(\n",
        "        inputs['input_ids'],\n",
        "        attention_mask=inputs['attention_mask'],\n",
        "        max_length=100,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        temperature=0.9,   # Slightly higher temperature for more variety\n",
        "        top_k=50,          # Limits the choices to the top 50 words\n",
        "        top_p=0.95,        # Uses cumulative probability to limit choices\n",
        "        no_repeat_ngram_size=2  # Prevents repeating the same 2-grams\n",
        "    )\n",
        "\n",
        "    # Decode the output\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "# Load the kural data (assuming it's stored in a JSON file as before)\n",
        "with open(\"/content/drive/MyDrive/THIRUKURAL/thirukural_git.json\", \"r\") as file:\n",
        "    kural_data = json.load(file)\n",
        "\n",
        "# Example usage\n",
        "query = \"What is the meaning of Kural number 5 in English?\"\n",
        "response = dispatcher(query, kural_data)\n",
        "print(response)\n",
        "\n",
        "query = \"What is  Thirukkural\"\n",
        "response = dispatcher(query, kural_data)\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2q4cE4c42WUI",
        "outputId": "36fe9e6e-af8f-4915-d38a-c303b9b24292"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kural 5: இருள்சேர் இருவினையும் சேரா இறைவன் பொருள்சேர் புகழ்புரிந்தார் மாட்டு.\n",
            "Meaning (English): The two-fold deeds that spring from darkness shall not adhere to those who delight in the true praise of God.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:520: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is  Thirukkural?\n",
            "\n",
            "Thirkur is a Sanskrit word meaning \"to be in the right place\". It is used in Sanskrit as a noun, and in English as an adjective.\n",
            ". It means \"in the wrong place\" or \"on the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT-4\n"
      ],
      "metadata": {
        "id": "CIGnvHPTXEnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "api_key = getpass('Enter your OpenAI API key: ')\n",
        "openai.api_key = api_key\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aGnnaaGciwj",
        "outputId": "2f3459b3-0830-48ab-e0ff-799c81ef66c4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL TRAINING & DISPATCHER GPT 3.5"
      ],
      "metadata": {
        "id": "obo0rcl7Ksax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the kural data\n",
        "def load_kural_data(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        return json.load(file)"
      ],
      "metadata": {
        "id": "VdY46pANyYzl"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to handle AI-based interactions using GPT-4\n",
        "def handle_ai_based(query):\n",
        "\n",
        "\n",
        "    try:\n",
        "        # Setup for the chat completion call\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo-0125\",\n",
        "\n",
        "\n",
        "\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a chatbot trained to answer questions about Thirukkural.You are an AI trained extensively on the Thirukkural, capable of understanding and responding in Tamil, English, and Tanglish.You have detailed knowledge of the commentaries by Mu. Varadarasanar and Salamon Pappaiya on the Thirukkural verses.You can provide explanations, interpret meanings, and relate verses to modern contexts as per the commentators' insights.\"},\n",
        "                {\"role\": \"user\", \"content\": query}\n",
        "            ],\n",
        "            temperature=0.7,\n",
        "            max_tokens=300\n",
        "        )\n",
        "        return response['choices'][0]['message']['content']\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {str(e)}\"\n",
        "\n",
        "def dispatcher(query, kural_data):\n",
        "    details = extract_query_details(query)\n",
        "\n",
        "    if details['query_type'] == 'kural_number' and 'kural_number' in details:\n",
        "        return get_thirukkural_response(kural_data, 'kural_number', details['kural_number'])\n",
        "    elif details['query_type'] == 'chapter_name' and 'chapter_name' in details:\n",
        "        return get_thirukkural_response(kural_data, 'chapter_name', details['chapter_name'])\n",
        "    else:\n",
        "        return handle_ai_based(query)\n",
        "\n",
        "\n",
        "def extract_query_details(query):\n",
        "    \"\"\"\n",
        "    Extracts details from the user's query. Attempts to determine the type of query\n",
        "    and extract relevant parameters such as the kural number.\n",
        "    \"\"\"\n",
        "    query = query.lower()\n",
        "    # Regular expression to find numeric patterns after 'kural number'\n",
        "    match = re.search(r\"kural number (\\d+)\", query)\n",
        "    if match:\n",
        "        return {'query_type': 'kural_number', 'kural_number': int(match.group(1))}\n",
        "\n",
        "    # Assuming 'chapter name' or 'section name' might also be part of the input\n",
        "    chapter_match = re.search(r\"chapter name (\\w+)\", query)\n",
        "    if chapter_match:\n",
        "        return {'query_type': 'chapter_name', 'chapter_name': chapter_match.group(1)}\n",
        "\n",
        "    # If the input does not match any known pattern\n",
        "    return {'query_type': 'free_text', 'query': query}\n",
        "\n",
        "# Assuming the rest of your functions and loading mechanisms are defined as in your previous examples\n",
        "\n",
        "\n",
        "# Load Thirukkural data\n",
        "kural_data = load_kural_data(\"/content/drive/MyDrive/THIRUKURAL/thirukural_git.json\")\n",
        "\n",
        "# Test the dispatcher\n",
        "query = \"What is the meaning of Kural number 5 in English?\"\n",
        "response = dispatcher(query, kural_data)\n",
        "print(response)\n",
        "\n",
        "query = \"How can Thirukkural apply to modern world friendship by MU VA?\"\n",
        "response = dispatcher(query, kural_data)\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwlMniptKwov",
        "outputId": "39b20b4d-3a2a-44dd-beee-3a14c8ed0247"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kural 5: இருள்சேர் இருவினையும் சேரா இறைவன் பொருள்சேர் புகழ்புரிந்தார் மாட்டு.\n",
            "Meaning (English): The two-fold deeds that spring from darkness shall not adhere to those who delight in the true praise of God.\n",
            "According to Mu. Varadarasanar, Thirukkural's teachings on friendship are highly relevant in the modern world. The verses on friendship emphasize the qualities of a true friend and the importance of fostering strong and genuine relationships. Here are some key points on how Thirukkural can apply to modern world friendship:\n",
            "\n",
            "1. **Trust and Loyalty**: Verse 793 states \"To keep his friend's counsel is a mark of true friendship.\" In the modern world, trust and loyalty are essential in friendships. Being able to confide in a friend and knowing that they will keep your secrets is crucial for a strong bond.\n",
            "\n",
            "2. **Support and Empathy**: Verse 794 highlights the importance of support in friendship, stating \"A friend is one who helps in times of need.\" In today's fast-paced world, having a friend who can empathize with your struggles and offer support is invaluable.\n",
            "\n",
            "3. **Mutual Respect**: Verse 795 emphasizes mutual respect in friendship, stating \"So long as both live, let friendship continue; the bond between friends should never be broken.\" Respecting each other's differences and choices is key to maintaining a healthy and lasting friendship.\n",
            "\n",
            "4. **Honesty and Communication**: Verse 796 stresses the importance of honesty in friendship, stating \"A friend who conceals faults is a true friend.\" In the modern world, open and honest communication is essential for resolving conflicts and strengthening relationships.\n",
            "\n",
            "5. **Selflessness and Sacrifice**: Verse \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL TRAINING & DISPATCHER GPT4"
      ],
      "metadata": {
        "id": "v9T5R2KWTaKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT-4"
      ],
      "metadata": {
        "id": "rDcqqMNIxoQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to handle AI-based interactions using GPT-4\n",
        "def handle_ai_based(query):\n",
        "\n",
        "\n",
        "    try:\n",
        "        # Setup for the chat completion call\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4\",\n",
        "\n",
        "\n",
        "\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a chatbot trained to answer questions about Thirukkural.You are an AI trained extensively on the Thirukkural, capable of understanding and responding in Tamil, English, and Tanglish.You have detailed knowledge of the commentaries by Mu. Varadarasanar and Salamon Pappaiya on the Thirukkural verses.You can provide explanations, interpret meanings, and relate verses to modern contexts as per the commentators' insights.\"},\n",
        "                {\"role\": \"user\", \"content\": query}\n",
        "            ],\n",
        "            temperature=0.7,\n",
        "            max_tokens=300\n",
        "        )\n",
        "        return response['choices'][0]['message']['content']\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {str(e)}\"\n",
        "\n",
        "def dispatcher(query, kural_data):\n",
        "    details = extract_query_details(query)\n",
        "\n",
        "    if details['query_type'] == 'kural_number' and 'kural_number' in details:\n",
        "        return get_thirukkural_response(kural_data, 'kural_number', details['kural_number'])\n",
        "    elif details['query_type'] == 'chapter_name' and 'chapter_name' in details:\n",
        "        return get_thirukkural_response(kural_data, 'chapter_name', details['chapter_name'])\n",
        "    else:\n",
        "        return handle_ai_based(query)\n",
        "\n",
        "\n",
        "def extract_query_details(query):\n",
        "    \"\"\"\n",
        "    Extracts details from the user's query. Attempts to determine the type of query\n",
        "    and extract relevant parameters such as the kural number.\n",
        "    \"\"\"\n",
        "    query = query.lower()\n",
        "    # Regular expression to find numeric patterns after 'kural number'\n",
        "    match = re.search(r\"kural number (\\d+)\", query)\n",
        "    if match:\n",
        "        return {'query_type': 'kural_number', 'kural_number': int(match.group(1))}\n",
        "\n",
        "    # Assuming 'chapter name' or 'section name' might also be part of the input\n",
        "    chapter_match = re.search(r\"chapter name (\\w+)\", query)\n",
        "    if chapter_match:\n",
        "        return {'query_type': 'chapter_name', 'chapter_name': chapter_match.group(1)}\n",
        "\n",
        "    # If the input does not match any known pattern\n",
        "    return {'query_type': 'free_text', 'query': query}\n",
        "\n",
        "# Assuming the rest of your functions and loading mechanisms are defined as in your previous examples\n",
        "\n",
        "\n",
        "# Load Thirukkural data\n",
        "kural_data = load_kural_data(\"/content/drive/MyDrive/THIRUKURAL/thirukural_git.json\")\n",
        "\n",
        "# Test the dispatcher\n",
        "query = \"What is the meaning of Kural number 5 in English?\"\n",
        "response = dispatcher(query, kural_data)\n",
        "print(response)\n",
        "\n",
        "query = \"How can Thirukkural apply to modern world friendship by MU VA?\"\n",
        "response = dispatcher(query, kural_data)\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ep6gsqO_tnW",
        "outputId": "5c0a7497-9109-41ba-ce20-b0997bc67f8f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kural 5: இருள்சேர் இருவினையும் சேரா இறைவன் பொருள்சேர் புகழ்புரிந்தார் மாட்டு.\n",
            "Meaning (English): The two-fold deeds that spring from darkness shall not adhere to those who delight in the true praise of God.\n",
            "Mu. Varadarajanar's commentary on Thirukkural provides profound insights into the nature of friendship and its importance in human life. He elucidates that Thirukkural's verses on friendship are timeless and fully applicable to the modern world.\n",
            "\n",
            "For instance, consider the verse 788: \"கூதினுள் யாழ்அமைந்த கோடி நூலினுள் யானை அமைந்த நூல்\". Mu. Varadarajanar interprets this as emphasizing the strength and resilience of true friendship. Just as a string passes through every bead in a garland, friendship weaves through every aspect of life. This is a universal truth that applies as much today as it did when Thirukkural was written.\n",
            "\n",
            "In the modern context, this could mean that true friendship isn't just about sharing good times, but also about standing by each other during difficult times. It could be interpreted that a friend should be supportive, reliable, and trustworthy, qualities that are crucial in today's fast-paced and often stressful world.\n",
            "\n",
            "Another verse (80) says: \"கேண்மை இல்லாயின் கேளாய\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT-4o"
      ],
      "metadata": {
        "id": "V6d4nhDxxe7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to handle AI-based interactions using GPT-4\n",
        "def handle_ai_based(query):\n",
        "\n",
        "\n",
        "    try:\n",
        "        # Setup for the chat completion call\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4o-2024-05-13\",\n",
        "\n",
        "\n",
        "\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a chatbot trained to answer questions about Thirukkural.You are an AI trained extensively on the Thirukkural, capable of understanding and responding in Tamil, English, and Tanglish.You have detailed knowledge of the commentaries by Mu. Varadarasanar and Salamon Pappaiya on the Thirukkural verses.You can provide explanations, interpret meanings, and relate verses to modern contexts as per the commentators' insights.\"},\n",
        "                {\"role\": \"user\", \"content\": query}\n",
        "            ],\n",
        "            temperature=0.7,\n",
        "            max_tokens=300\n",
        "        )\n",
        "        return response['choices'][0]['message']['content']\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {str(e)}\"\n",
        "\n",
        "def dispatcher(query, kural_data):\n",
        "    details = extract_query_details(query)\n",
        "\n",
        "    if details['query_type'] == 'kural_number' and 'kural_number' in details:\n",
        "        return get_thirukkural_response(kural_data, 'kural_number', details['kural_number'])\n",
        "    elif details['query_type'] == 'chapter_name' and 'chapter_name' in details:\n",
        "        return get_thirukkural_response(kural_data, 'chapter_name', details['chapter_name'])\n",
        "    else:\n",
        "        return handle_ai_based(query)\n",
        "\n",
        "\n",
        "def extract_query_details(query):\n",
        "    \"\"\"\n",
        "    Extracts details from the user's query. Attempts to determine the type of query\n",
        "    and extract relevant parameters such as the kural number.\n",
        "    \"\"\"\n",
        "    query = query.lower()\n",
        "    # Regular expression to find numeric patterns after 'kural number'\n",
        "    match = re.search(r\"kural number (\\d+)\", query)\n",
        "    if match:\n",
        "        return {'query_type': 'kural_number', 'kural_number': int(match.group(1))}\n",
        "\n",
        "    # Assuming 'chapter name' or 'section name' might also be part of the input\n",
        "    chapter_match = re.search(r\"chapter name (\\w+)\", query)\n",
        "    if chapter_match:\n",
        "        return {'query_type': 'chapter_name', 'chapter_name': chapter_match.group(1)}\n",
        "\n",
        "    # If the input does not match any known pattern\n",
        "    return {'query_type': 'free_text', 'query': query}\n",
        "\n",
        "# Assuming the rest of your functions and loading mechanisms are defined as in your previous examples\n",
        "\n",
        "\n",
        "# Load Thirukkural data\n",
        "kural_data = load_kural_data(\"/content/drive/MyDrive/THIRUKURAL/thirukural_git.json\")\n",
        "\n",
        "# Test the dispatcher\n",
        "query = \"What is the meaning of Kural number 5 in English?\"\n",
        "response = dispatcher(query, kural_data)\n",
        "print(response)\n",
        "\n",
        "query = \"KURAL 999\"\n",
        "response = dispatcher(query, kural_data)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Buw9TGWkpvrQ",
        "outputId": "5f818688-55f5-48a8-aab3-488e7ac69ba9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kural 5: இருள்சேர் இருவினையும் சேரா இறைவன் பொருள்சேர் புகழ்புரிந்தார் மாட்டு.\n",
            "Meaning (English): The two-fold deeds that spring from darkness shall not adhere to those who delight in the true praise of God.\n",
            "Certainly! Thirukkural 999 is from the chapter on \"Neglect of Duty\" (ஒழுக்கமுடைமை).\n",
            "\n",
            "Here is the Kural in Tamil:\n",
            "நட்டார்போல் எய்தியக் கண்ணும் கெடுதகைமை\n",
            "சுட்டார் அறியார் பகை.\n",
            "\n",
            "Transliteration:\n",
            "Naṭṭār pōl eythiyak kaṇṇum keṭutakaimai\n",
            "Suṭṭār aṟiyār pakai.\n",
            "\n",
            "Translation:\n",
            "Even when they appear like friends, their enmity is known only when they harm openly.\n",
            "\n",
            "Explanation:\n",
            "According to the commentary by Mu. Varadarasanar, this Kural emphasizes the hidden enmity that can exist beneath the guise of friendship. It suggests that even those who seem to be friends can harbor ill intentions, and their true nature is revealed only when they cause harm. This verse advises caution and discernment in relationships, highlighting the importance of recognizing and understanding the true intentions of those around us.\n",
            "\n",
            "Salamon Pappaiya's commentary might elaborate further on the nuances of human behavior and relationships, emphasizing the need for vigilance and wisdom in assessing the sincerity of others to avoid potential harm.\n",
            "\n",
            "In the modern context, this Kural can be related to the idea of being cautious about whom to trust and understanding that not everyone who appears friendly has genuine intentions. It underscores the importance of being prudent and perceptive in personal and professional relationships.\n"
          ]
        }
      ]
    }
  ]
}